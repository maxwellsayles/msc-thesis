\documentclass[11pt, letterpaper]{article}
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage{amsthm}
\usepackage{url}
\usepackage{fullpage}
\usepackage{verbatim}

\usepackage{theorem}
\theorembodyfont{\rmfamily}

\newenvironment{definition}
{\noindent\begin{defn}}
{\hfill $\Box$ \end{defn}}
\newtheorem{defn}{Definition}

\newenvironment{theorem}
{\noindent\begin{thm}}
{\hfill $\Box$ \end{thm}}
\newtheorem{thm}{Theorem}

\newenvironment{corollary}
{\noindent\begin{cor}}
{\hfill $\Box$ \end{cor}}
\newtheorem{cor}{Corollary}

\newenvironment{lemma}
{\noindent\begin{lem}}
{\hfill $\Box$ \end{lem}}
\newtheorem{lem}{Lemma}

\newenvironment{proposition}
{\noindent\begin{prop}}
{\hfill $\Box$ \end{prop}}
\newtheorem{prop}{Proposition}




\parindent 0ex

\newcommand{\CC}{\mathbb{C}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\matrixot}[2]{\left( \begin{array}{c} #1 \\ #2 \end{array} \right)}
\newcommand{\matrixtt}[4]{\left( \begin{array}{cc} #1 & #2 \\ #3 & #4 \end{array} \right)}
\newcommand{\ntoinfty}{\lim_{n \rightarrow \infty}}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}



\begin{document}

\title{Summary of definitions and theorems\\from Aldous 1999}
\maketitle

Let $P = p_{ij}$ be the transition matrix from state $s_i$ to state $s_j$ for the discrete-time Markov chain $(X_t : t = 0, 1, 2, ...)$ where $X_t$ is a random variable over a sample space.  The $t$-step transition probabilities are $Pr(X_t = j | X_0 = i) = p^{(t)}_{ij}$ where $P^{(t)}$ is the $t$-fold matrix product.  The transition matrix $P$ also denotes an adjacency matrix for a directed graph.  Aldous uses $Z$ to denote the fundamental matrix of $P$ and $I$ to denote the sample set, i.e. the set of states the chain can be in.

\begin{definition}
\textit{Mean cover time}: The time to visit every vertex of a graph.
\end{definition}

\begin{definition}
\textit{Self-avoiding walk}: A walk from one vertex on a graph to another vertex on a graph such that no edge crosses the path already taken.  In other words, a sequence of moves on a lattice that doesn't visit the same point twice.
\end{definition}


\begin{definition}
\textit{First Hitting time}:  The time until a state is first visited is called the \textit{first hitting time}.  We write 
\[
	T_i = \min \{ t \ge 0 : X_t = i\}
\]
for the first hitting time for state $s_i$ and more generally,
\[
	T_A = \min \{ t \ge 0 : X_t \in A \}
\]
for a subset $A$ of states.
\end{definition}

\begin{definition}
\textit{First return time}: The first return time is the minimal number of steps to return to state $s_i$ if started in state $s_i$.  We write
\[
	{T_i}^+ = \min \{ t \ge 1 : X_t = i \}
\]
for the first return time for state $s_i$.
\end{definition}


\begin{definition}
\textit{Irreducible}: A chain is \textit{irreducible} if it is possible to move from any state to any state not necessary in one move.  Another way of thinking about this is that the graph represented by the transition matrix is a connected graph.  Snell refers to this as an \textit{ergodic} chain.
\end{definition}

\begin{definition}
\textit{Stationary Distribution}: If a chain is irreducible, then there exists a unique \textit{stationary distribution} $\pi$ such that $\pi P = \pi$.  (Snell refers to this as the \textit{fixed product vector}, $w$.)  If the initial state of a chain is random with respect to the stationary distribution $\pi$, then any subsequent non-random time $t$ will result in a state at $X_t$ with the same distribution as $\pi$.  Such a chain is called the \textit{stationary chain}.
\end{definition}

\begin{theorem}
Let $N_i(t)$ be the number of visits to state $s_i$ during times $0, 1, ... , t-1$.  Then for any initial distribution
\[
	\lim_{t \rightarrow \infty} \frac{N_i(t)}{t} = \pi_i.
\]
This is known as the ergodic theorem.
\end{theorem}

\begin{theorem}
For any initial distribution on a aperiodic (regular) chain,
\[
	\forall_j \lim_{t \rightarrow \infty} Pr(X_t=j) = \pi_j.
\]
This is known as the convergence theorem.
\end{theorem}


\begin{definition}
\textit{Jump chain}: Define a transition matrix $J$ by
\[
	J_{ij} = \begin{cases}
			0 & \mbox{if } i = j \\
			\frac{q_{ij}}{q_i} & \mbox{otherwise}
	         \end{cases}
\]
and the discrete-time chain $X^J$ is called the \textit{jump chain} associated with $X_t$.
\end{definition}



\begin{definition}
\textit{Mixing time}: The number of steps, $n$, until the distribution is approximately the stationary distribution, i.e. $P^n = W$ is known as the \textit{mixing time}.
\end{definition}

\begin{definition}
\textit{Aperiodic}: An \textit{aperiodic} chain is a chain such that it is possible to get from any state to any state in precisely $n$ steps. (Snell refers to such as chain as \textit{regular}.)
\end{definition}

\begin{theorem}
In discrete time, consider the number $N_i(t)$ of visits to state $s_i$ before time $t$.  For a stationary chain we have
\[
	E_{\pi}N_i(t) = t\pi_i.
\]
The variance for other chains is
\[
	\textrm{var}_\pi N_i(t) = \sum_{r=0}^{t-1} \sum_{s=0}^{t-1} ( P_\pi (X_r = i, X_s = i) - \pi_i^2).
\]
Setting $u = |s-r|$, the above simplifies to:
\[
	\textrm{var}_\pi N_i(t) = \pi_i \left( \sum_{u=0}^{t-1} 2(t-u)(p_{ii}^{(u)} - \pi_i) - t(1-\pi_i) \right).
\]
This gives us the following asymptotic result
\[
	\frac{\textrm{var}_\pi N_i(t)}{t} \rightarrow \pi_i(2Z_{ii} - 1 + \pi_i).
\]

\textbf{(The above theorem is questionable, since the brute force computation of a few simple graphs show that the results do not match for the theorem given above).}
\end{theorem}

Different notions of distance will give different numerical results.

\begin{definition}
\textit{Variation distance}: A notion of distance between probability distributions defined as
\[
	||\theta_1 - \theta_2|| = \max_{A \subseteq I}  | \theta_1(A) - \theta_2(A) |.
\]
In this sense, variation distance is the maximum \textit{additive} error between probability distributions.
\end{definition}

\begin{theorem}
As a measure of deviation from stationarity at time $t$, for the chain started at state $i$, we may use:
\[
	d_i(t) = ||Pr_i(X_t = \cdot) - \pi(\cdot)||.
\]
The worst-case deviation from stationarity is then given by:
\[
	d(t) = \max_i d_i(t).
\]
\end{theorem}

\begin{definition}
The $L^2$ norm of a function $f : I \rightarrow R$ is
\[
	||f||_2 = \sqrt {\sum_i \pi_i f^2(i)}.
\]
The $L^2$ norm of a signed measure is given by:
\[
	||v||_2 = \sqrt {\sum_i \frac{v_i^2}{\pi_i}}
\]
where the $L^2$ norm of a measure $v$ is defined to be the $L^2$ norm of its density function.
\end{definition}

\begin{theorem}
The $L^2$ measure of distance between a probability distributions $\theta$ and the stable distribution $\pi$ is given by:
\begin{eqnarray*}
	||\theta - \pi||_2 & = & \sqrt{ \sum_i \frac{(\theta_i - \pi_i)^2}{\pi_i}} \\
	& = & \sqrt{ \sum_i \frac{\theta_i^2}{\pi_i} - 1}.
\end{eqnarray*}
\end{theorem}

\begin{definition}
$L^1$ norms are given as
\[
	||f||_1 = \sum_i \pi_i |f(i)|
\]
and
\[
	||v||_1 = \sum_i |v_i|.
\]
\end{definition}

\begin{theorem}
For any $n$-state markov chain, Mathew's method gives an upper and lower bound on the cover-time.
\begin{eqnarray*}
	\max_v E_v C & \le & h_{n-1} \max_{i,j} E_i T_j \\
	\min_v E_v C & \ge & h_{n-1} \min_{i \ne j} E_i T_j
\end{eqnarray*}
where $h_{n-1} = \sum_{m=1}^{n-1} \frac{1}{m}$.
\end{theorem}


\begin{definition}
The spectral representation $S$ of a finite-state, irreducible, reversible chain is given by:
\[
	s_{ij} = \sqrt{\frac{\pi_i}{\pi_j}}  p_{ij}.
\]
\end{definition}

\begin{corollary}
For reversible chains,
\[
	E_\pi T_j - E_\pi T_i = E_i T_j - E_j T_i.
\]
\end{corollary}




\end{document}

