\documentclass{ucalgthes1}   
\usepackage[letterpaper,top=1in, bottom=1.22in, left=1.40in, right=0.850in]{geometry}
\usepackage{fancyhdr}
\fancyhead{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\fancyhead[RO,LE]{\thepage}  
\usepackage{hyperref}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{comment}
\usepackage{float}
\usepackage{graphics}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}

\usepackage{eqparbox}
\renewcommand{\algorithmiccomment}[1]{\hfill\eqparbox{COMMENT}{#1}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\sign}{sign}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\OO}{\mathcal{O}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NP}{\textrm{NP}}
\newcommand{\RRgtz}{\mathbb{R}_{>0}}
\newcommand{\ZZgtz}{\mathbb{Z}_{>0}}
\newcommand{\ZZgez}{\mathbb{Z}_{\ge 0}}
\newcommand{\QQgtz}{\mathbb{Q}_{>0}}
\newcommand{\QQgez}{\mathbb{Q}_{\ge 0}}
\newcommand{\matrixto}[2]{\left[ \begin{array}{rr} #1 & #2 \end{array} \right]}
\newcommand{\matrixot}[2]{\left[ \begin{array}{r} #1 \\ #2 \end{array} \right]}
\newcommand{\matrixtt}[4]{\left[ \begin{array}{rr} #1 & #2 \\ #3 & #4 \end{array} \right]}
\newcommand{\matrixThreeTwo}[6]{\left[ \begin{array}{rrr} #1 & #2 & #3 \\ #4 & #5 & #6 \end{array} \right]}
\newcommand{\ntoinfty}{\lim_{n \rightarrow \infty}}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\amax}{a_\textrm{max}}
\newcommand{\bmax}{b_\textrm{max}}

\begin{document}

\setcounter{chapter}{1}

%%%%%%%%%%%%%%%%%%%%
% CHAPTER 2        %
% IDEAL ARITHMETIC %
%%%%%%%%%%%%%%%%%%%%
\chapter{Ideal Arithmetic}
\label{chap:idealArithmetic}

A focus of this thesis is arithmetic and exponentiation in the ideal class group of imaginary quadratic number fields.  We begin with the relevant theory of quadratic number fields, then discuss quadratic orders and ideals of quadratic orders.  Finally, we discuss arithmetic in the ideal class group.  The theory presented here is available in detail in reference texts on algebraic number theory such as \cite{Cohn1980}, \cite{Hua2012}, or \cite{Ireland1990}. 



%%%%%%%%%%%%%%%%%%%%%
% QUADRATIC NUMBERS %
%%%%%%%%%%%%%%%%%%%%%
\section{Quadratic Numbers}

A \emph{quadratic number} is a root $\alpha$ of a quadratic polynomial $f(x) = ax^2 + bx + c$ with integer coefficients. The roots of $f(x)$ are given by the quadratic formula
\[
	\alpha = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a} ~.
\]
The \emph{discriminant} of $f(x)$ is $\Delta = b^2 - 4ac$, and we can construct a quadratic number field $\KK$ as an extension field of the rational numbers $\QQ$ as
\[
	\KK = \QQ(\alpha) = \QQ(\sqrt{\Delta}) = \{u + v\sqrt{\Delta} : u,v \in \QQ\}.
\]
When $\Delta$ is positive, $\KK$ is a subset of the real numbers, $\RR$, and is a \emph{real} quadratic number field. When $\Delta$ is negative, $\KK$ is a subset of the complex numbers, $\CC$, and is an \emph{imaginary} quadratic number field.  In this thesis we concern ourselves only with the imaginary case.  Notice that if $\Delta = f^2 \Delta_0$ for some $f \in \ZZgtz$ where $\Delta_0$ is square-free, then $\QQ(\sqrt{\Delta}) = \QQ(\sqrt{\Delta_0})$. For $\Delta_0$ to be square-free, it must be that $\Delta_0 \not\equiv 0 \pmod 4$ since this would imply that $\Delta_0$ is divisible by 4, a perfect square.  


%%%%%%%%%%%%%%%%%%%%%%
% QUADRATIC INTEGERS %
%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\section{Quadratic Integers}

A polynomial with a leading coefficient of 1 is a \emph{monic} polynomial, and the root $\alpha$ of a monic polynomial $f(x)$ with integer coefficients is an \emph{algebraic integer}. The rational numbers are degree 1 algebraic numbers since they are roots of degree 1 polynomials $bx-a$.  The roots of monic degree 1 polynomials $x-a$ are the integers, $\ZZ$.  When $f(x)$ is a monic quadratic polynomial with integer coefficients, the root $\alpha$ is a \emph{quadratic integer}. By \cite[p.77]{Jacobson2009} we have the following theorem:

\begin{thm}
A quadratic integer $\alpha$ is an algebraic integer of $\QQ(\sqrt{\Delta_0})$ where $\alpha$ can be written as $\alpha = x + y \omega_0$ for $x, y \in \ZZ$ where
\begin{equation*}
	\omega_0 = \begin{cases}
		\sqrt{\Delta_0} & \textrm{ when } \Delta_0 \equiv 2, 3 \pmod 4 \\
		\frac{1+\sqrt{\Delta_0}}{2} & \textrm{ when } \Delta_0 \equiv 1 \pmod 4.
	\end{cases}
\end{equation*}
\end{thm}


%%%%%%%%%%%%%%%%%
% MAXIMAL ORDER %
%%%%%%%%%%%%%%%%%
\bigbreak
\section{Maximal Order of Algebraic Integers}

The \emph{maximal order} of a field $\KK$ is the set of all algebraic integers contained within $\KK$.  We use the notation of $\ZZ$-modules to characterize the maximal order of quadratic integers.


\begin{defn}
Let $X = \{ \xi_1, \xi_2, \xi_3, ..., \xi_n \}$ be a subset of a number field $\KK$.  A \emph{$\ZZ$\mbox{-}module}, $\MM$, is a finitely generated additive abelian group such that
\begin{align*}
	\MM &= [ \xi_1, \xi_2, ..., \xi_n ] \\
	& =  \xi_1 \ZZ + \xi_2 \ZZ + \cdots + \xi_n \ZZ \\
	& = \left \{ \sum_{i}^n x_i \xi_i : x_i \in \ZZ, \xi_i \in X \right \}.
\end{align*}
\end{defn}

\begin{thm}
A \emph{quadratic order} $\OO_\Delta$ of $\QQ(\sqrt\Delta)$ is a sub-ring of the quadratic integers of $\QQ(\sqrt\Delta)$ containing 1.  Following \cite[p.81]{Jacobson2009}, we write $\OO_\Delta$ as
\[
	\left[ 1, \frac{\Delta + \sqrt{\Delta}}{2} \right] = [1, f\omega_0].
\]
The maximal order $\OO_\Delta = [1, \omega_0]$ of $\QQ(\sqrt\Delta_0)$ is the ring of all quadratic integers in $\QQ(\sqrt\Delta_0)$.  This order is maximal since any other order $\OO = [1, f\omega_0]$ is a sub-ring of $\OO_\Delta$. 
\end{thm}


%%%%%%%%%%
% IDEALS %
%%%%%%%%%%
\bigbreak
\section{Ideals of $\OO_\Delta$}

\begin{defn}
An \emph{ideal} $\mathfrak a$ is an additive subgroup of an order $\OO$ with the property that for any $a \in \mathfrak a$ and $\xi \in \OO$, it holds that $\xi a$ and $a \xi$ are both elements of the ideal $\mathfrak a$.
\end{defn}

For any $\alpha, \beta \in \OO_\Delta$, the set $\{x \alpha + y \beta : x, y \in \OO_\Delta\}$ is an ideal $\mathfrak a$ in the order $\OO_\Delta$.  We say that $\mathfrak a$ is generated by $\alpha$ and $\beta$ and denote it $(\alpha, \beta)$.  Every ideal $\mathfrak a$ of a quadratic order $\OO_\Delta$ can be represented by at most two generators \cite{Cohn1980}, but some can be represented by only a single generator. An ideal represented by a single generator, $\alpha \in \OO_\Delta$, is denoted $(\alpha)$ and is called \emph{principal} \cite[p.87]{Jacobson2009}.

\begin{thm}
\label{thm:idealZModule}
When $\OO_\Delta = [1, f\omega_0]$ is the order of a quadratic field, a non-zero ideal $\mathfrak a$ of $\OO_\Delta$ can be uniquely written as a two dimensional $\ZZ$-module 
\[
	\mathfrak a = s\left[a, \frac{b+\sqrt{\Delta}}{2} \right]
\]
for $s, a, b \in \ZZ, s > 0, a > 0$, $\gcd(a, b, (b^2-\Delta)/4a)=1$, $b^2 \equiv \Delta \pmod{4a}$, and $b$ is unique $\bmod ~2a$ \cite[p.13]{Jacobson1999}. When $s = 1$, the ideal $\mathfrak a$ is \emph{primitive}.
\end{thm}

The \emph{identity} ideal is $\OO_\Delta = [1, f\omega_0]$ since $\mathfrak a = \mathfrak a \OO_\Delta = \OO_\Delta \mathfrak a$ \cite{Cohn1980}. An ideal $\mathfrak a = s[a, (b+\sqrt{\Delta})/2]$ is \emph{invertible} if there exists an ideal $\mathfrak b$ such that $\mathfrak a \mathfrak b = \OO_\Delta$, and an ideal $\mathfrak b$ exists when $\gcd(a, b, (b^2-\Delta)/(4a)) = 1$ \cite[p.14]{Jacobson1999}. The inverse is given by \cite[pp.14,15]{Jacobson1999}
\[
	{\mathfrak a}^{-1} = \frac{s}{\mathcal N(\mathfrak a)} \left[a, \frac{-b+\sqrt{\Delta}}{2} \right]
\]
where $\mathcal N(\mathfrak a) = s^2a$ is the norm of $\mathfrak a$ and is multiplicative. When $\OO_\Delta$ is maximal, all ideals of $\OO_\Delta$ are invertible. 

Prime ideals allow us to easily create an ideal.  For a prime ideal $\mathfrak p \in \OO_\Delta$ it can be shown (\cite[p.19]{Jacobson1999}) that $\mathfrak p \cap \ZZ = p\ZZ$ for some prime integer $p \in \ZZ$. Let
\[
	\mathfrak p = s\left[a, \frac{b + \sqrt{\Delta}}{2}\right]
\]
and it follows that either $s=p$ and $a=1$, or $s=1$ and $a=p$.  In the first case $\mathfrak p = p\OO_\Delta$, while in the second case $b = \pm \sqrt{\Delta} \pmod p$ and $\mathfrak p = [p, (b + \sqrt{\Delta})/2]$ when $4p ~|~ b^2 - \Delta$.  Algorithm \ref{alg:prime} gives pseudo-code.

% PRIME
\bigbreak
\begin{algorithm}[h]
\caption{Prime Ideal}
\label{alg:prime}
\begin{algorithmic}[1]
\REQUIRE A prime integer $p \in \ZZ$.
\ENSURE A representative $\mathfrak p = [p, (b+\sqrt\Delta)/2]$ such that $\mathfrak p$ is a prime ideal if one exists.
\STATE $b \gets \textrm{the positive } \sqrt\Delta \pmod p$
\IF {$4p ~|~ b^2-\Delta$}
	\RETURN $[p, (b+\sqrt\Delta)/2]$
\ENDIF
\STATE $b \gets p-b$
\IF {$4p ~|~ b^2-\Delta$}
	\RETURN $[p, (b+\sqrt\Delta)/2]$
\ENDIF
\RETURN none
\end{algorithmic}
\end{algorithm}

Two ideals $\mathfrak a$ and $\mathfrak b$ are \emph{equivalent} if there exists $\alpha, \beta \in \OO_\Delta$ such that $\alpha \beta \neq 0$ and $(\alpha)\mathfrak a = (\beta) \mathfrak b$ \cite[p.88]{Jacobson2009}. Following \cite[p.88]{Jacobson2009}, we denote by $[\mathfrak a]$ the \emph{ideal class} of all ideals equivalent to $\mathfrak a$. 


%%%%%%%%%%%%%%%%%%%%%
% IDEAL CLASS GROUP %
%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\section{Ideal Class Group}

Recall that two ideals $\mathfrak a$ and $\mathfrak b$ are equivalent if there exists principal ideals $(\alpha)$ and $(\beta)$ such that $(\alpha)\mathfrak a = (\beta)\mathfrak b$.  An ideal class $[\mathfrak a]$ is the set of all ideals that are equivalent to $\mathfrak a$. As such, an ideal $\mathfrak a$ is a \emph{representative} for the ideal class $[\mathfrak a]$. The \emph{ideal class group}, $Cl_\Delta$, is the set of all equivalence classes of invertible $\OO$-ideals, with the group operation defined as the product of class representatives.

Our implementation of ideal arithmetic represents an ideal as $\mathfrak a = [a, (b + \sqrt\Delta)/2]$ where $\mathfrak a$ is primitive.  Additionally, we carry around the value $c = (b^2 - \Delta)/4a$.  We represent the class group by the discriminant $\Delta$. Since an ideal class contains an infinitude of ideals, we work with reduced representatives.  This also makes arithmetic faster, since the size of generators are typically smaller.

In Subsection \ref{subsec:reduction}, we state what it is for an ideal to be in reduced form, and in subsection \ref{subsec:idealMultiply}, we show how to multiply two reduced class representatives. In Subsection \ref{subsec:nucomp} we discuss how to perform multiplication such that the result is a reduced or almost reduced representative, and then extend this to the case of computing the square (\ref{subsec:nudupl}) and cube (\ref{subsec:nucube}) of an ideal class.  


%%%%%%%%%%%%%
% REDUCTION %
%%%%%%%%%%%%%
\subsection{Reduced Representatives}
\label{subsec:reduction}

\begin{defn}
A primitive ideal $\mathfrak{a} = [a, (b+\sqrt{\Delta})/2]$ with $\Delta < 0$ is \emph{reduced} when $-a < b \le a < c$ or when $0 \le b \le a = c$ for $c = (b^2 - \Delta)/4a$ \cite[p.241]{Crandall2001}.
\end{defn}

% REDUCE
\begin{algorithm}[h]
\caption{Ideal Reduction}
\label{alg:reduce}
\begin{algorithmic}[1]
\REQUIRE An ideal class representative $\mathfrak a_1 = [a_1, (b_1+\sqrt\Delta)/2]$ and $c_1 = ({b_1}^2 - \Delta)/4a_1$.
\ENSURE A reduced representative $\mathfrak a = [a, (b+\sqrt\Delta)/2]$.
\STATE $(a, b, c) \gets (a_1, b_1, c_1)$
\WHILE {$a > c$ or $b > a$ or $b \le -a$}
	\IF {$a > c$}
		\STATE swap $a$ with $c$ and let $b \gets -b$
	\ENDIF
	\IF {$b > a$ or $b \le -a$}
		\STATE $b \gets b'$ such that $-a < b' \le a$ and $b' \equiv b \pmod{2a}$
		\STATE $c \gets (b^2-\Delta)/4a$
	\ENDIF
\ENDWHILE
\IF {$a=c$ and $b < 0$}
	\STATE $b \gets -b$
\ENDIF
\RETURN $[a, (b+\sqrt\Delta)/2]$
\end{algorithmic}
\end{algorithm}

In an imaginary quadratic field, every ideal class contains exactly one reduced ideal \cite[p.20]{Ramachandran2006}.  There are several algorithms to compute a reduced ideal, many of which are listed in \cite{Jacobson2006}.  Here we present the algorithm we use.  We adapt the work presented on \cite[p.90]{Jacobson2006} and \cite[p.99]{Jacobson2009}. If $\mathfrak a = [a, (b + \sqrt\Delta)/2]$ is a primitive ideal then 
\begin{equation}
\label{eq:idealSwapNorm}
	\mathfrak b = \left[ -\mathcal N((b + \sqrt\Delta)/2)/a, -(b - \sqrt\Delta)/2 \right]
\end{equation}
is also a primitive ideal, since we can verify that
\[
	\left(-(b - \sqrt\Delta)/2 \right) \mathfrak a = (a) \mathfrak b.
\]
Simplifying Equation \ref{eq:idealSwapNorm} we get
\[
	\mathfrak b = \left[ \frac{b^2-\Delta}{4a}, \frac{-b + \sqrt\Delta}{2} \right].
\]
Since $c = (b^2 - \Delta)/4a$ we have
\begin{equation}
\label{eq:idealSwapAC}
	\mathfrak b = \left[ c, \frac{-b + \sqrt\Delta}{2} \right].
\end{equation}
As such, the first step is if $a > c$, we can reduce $a$ by setting $\mathfrak a = [c, (-b + \sqrt\Delta)/2]$.  Since $b$ is unique $\bmod{~2a}$, we can also reduce $b \bmod{2a}$.  We repeat these steps while $\mathfrak a$ is not reduced.  In the case that $a = c$, we use the absolute value of $b$, since by Equation \ref{eq:idealSwapAC} the ideals $[a, (b + \sqrt\Delta)/2]$ and $[c, (-b+\sqrt\Delta)/2]$ are equivalent.  Pseudo-code is given in Algorithm \ref{alg:reduce}.


%%%%%%%%%%%%%%%%%%
% MULTIPLICATION %
%%%%%%%%%%%%%%%%%%
\subsection{Multiplication of Ideal Classes}
\label{subsec:idealMultiply}

The ideal class group operation is multiplication of ideal class representatives. Given two representative ideals $\mathfrak a = [a_1, (b_1 + \sqrt{\Delta})/2]$ and $\mathfrak b = [a_2, (b_2 + \sqrt{\Delta})/2]$ in reduced form, the (non-reduced) product $\mathfrak a \mathfrak b$ can computed using
\begin{align}
	c_2 & = ({b_2}^2-\Delta)/4a_2, \\
	s & = \gcd(a_1, a_2, (b_1+b_2)/2) = Ya_1 + Va_2 + W(b_1+b_2)/2,    \label{eq:idealProductS} \\
	U & = (V(b_1-b_2)/2 - Wc_2) \bmod{(a_1/s)},                        \label{eq:idealProductU} \\
	a & = (a_1a_2)/s^2,                                                \label{eq:idealProductA} \\
	b & = (b_2 + 2Ua_2/s) \bmod{2a},                                   \label{eq:idealProductB} \\
	\mathfrak a \mathfrak b & = s\left[a, \frac{b + \sqrt{\Delta}}{2}\right].
\end{align}

The remainder of this subsection is used to derive the above equations.  We adapt much of the presentation given in \cite[pp.117,118]{Jacobson2009}. Component-wise multiplication of $\mathfrak a$ and $\mathfrak b$ give us
\begin{equation}
\label{eq:productExpanded}
\mathfrak{a} \mathfrak{b} =
\left[ a_1a_2, \frac{a_1b_2 + a_1\sqrt{\Delta}}{2}, \frac{a_2b_1 + a_2\sqrt{\Delta}}{2}, \frac{b_1b_2 + (b_1+b_2)\sqrt{\Delta} + \Delta}{4} \right].
\end{equation}

\noindent
By the multiplicative property of the norm we have
\begin{align*}
	& N(\mathfrak{a}\mathfrak{b}) = s^2a = N(\mathfrak{a})N(\mathfrak{b}) = a_1 a_2 \\
	\Rightarrow~ & a = \frac{a_1a_2}{s^2},
\end{align*}
which gives us Equation \ref{eq:idealProductA}. Now, by the second term of equation \eqref{eq:productExpanded} we know that $(a_1b_2 + a_1\sqrt{\Delta})/2 \in \mathfrak{a}\mathfrak{b}$.  It follows that there is some $x,y \in \ZZ$ such that
\[
	\frac{a_1b_2 + a_1\sqrt{\Delta}}{2} = xsa + ys\left(\frac{b+\sqrt{\Delta}}{2}\right).
\]
Equating irrational parts we have
\begin{equation*}
	\frac{a_1\sqrt{\Delta}}{2} = \frac{ys\sqrt{\Delta}}{2}.
\end{equation*}
\noindent
Hence, $s ~|~ a_1$.  Similarly, by the third and fourth terms of equation \eqref{eq:productExpanded} we have $(a_2b_1+a_2\sqrt{\Delta})/2 \in \mathfrak{a}\mathfrak{b}$, which implies that $s~|~a_2$, and $(b_1b_2 + (b_1+b_2)\sqrt{\Delta} + \Delta)/4 \in \mathfrak{a}\mathfrak{b}$, which implies that $s~|~(b_1+b_2)/2$. 

By the second generator, $s(b+\sqrt\Delta)/2$, of $\mathfrak{a}\mathfrak{b}$ and the entire right hand side of equation \eqref{eq:productExpanded} there exists $X, Y, V, W \in \ZZ$ such that
\[
\frac{sb+s\sqrt\Delta}{2} = Xa_1a_2 + Y\frac{a_1b_2+a_1\sqrt\Delta}{2} + V\frac{a_2b_1 + a_2\sqrt{\Delta}}{2} + W\frac{b_1b_2 + (b_1+b_2)\sqrt{\Delta} + \Delta}{4}.
\]
Grouping rational and irrational parts, we have
\begin{equation}
\label{eq:productSecond}
\frac{sb+s\sqrt\Delta}{2} = \left( Xa_1a_2 + Y\frac{a_1b_2}{2} + V\frac{a_2b_1}{2} + W\frac{b_1b_2 + \Delta}{4} \right) + \left(Y\frac{a_1}{2} + V\frac{a_2}{2} + W\frac{b_1+b_2}{4}\right)\sqrt\Delta. 
\end{equation}

\noindent
Again, by equating irrational parts we have
\begin{align}
	\frac{s\sqrt\Delta}{2} & = \left(Y\frac{a_1}{2} + V\frac{a_2}{2} + W\frac{b_1+b_2}{4}\right)\sqrt\Delta \nonumber \\
	s & = Ya_1 + Va_2 + W\frac{b_1+b_2}{2}, \label{eq:sAsGCD}
\end{align}
which is the same as Equation \ref{eq:idealProductS}.  Since $s$ divides each of $a_1, a_2,$ and $(b_1+b_2)/2$, we have that $s = \gcd(a_1, a_2, (b_1+b_2)/2)$.

It remains to compute $b \pmod{2a}$.  Recall that $a = a_1a_2/s^2$.  This time, by equating the rational parts of \eqref{eq:productSecond} we have:
\begin{align}
	\frac{sb}{2} & = Xa_1a_2 + Y\frac{a_1b_2}{2} + V\frac{a_2b_1}{2} + W\frac{b_1b_2 + \Delta}{4} \nonumber \\
	b & = 2X\frac{a_1a_2}{s} + Y\frac{a_1b_2}{s} + V\frac{a_2b_1}{s} + W\frac{b_1b_2 + \Delta}{2s} \nonumber \\
	b & \equiv Y\frac{a_1b_2}{s} + V\frac{a_2b_1}{s} + W\frac{b_1b_2 + \Delta}{2s} \pmod{2a} \label{eq:bMod2a}
\end{align}

\noindent
This gives us $b$.  However, we can rewrite \eqref{eq:bMod2a} with fewer multiplies and divides.  By equation \eqref{eq:sAsGCD}, we have
\begin{align*}
	s & = Ya_1 + Va_2 + W\frac{b_1+b_2}{2} \\
	1 & = Y\frac{a_1}{s} + V\frac{a_2}{s} + W\frac{b_1+b_2}{2s} \\
	Y\frac{a_1}{s} & = 1 - V\frac{a_2}{s} - W\frac{b_1+b_2}{2s}.
\end{align*}

\noindent
Substituting into equation \eqref{eq:bMod2a} we get
\begin{alignat*}{2}
	b & \equiv b_2(1-V\frac{a_2}{s} - W\frac{b_1+b_2}{2s}) + V\frac{a_2b_1}{s} + W\frac{b_1b_2 + \Delta}{2s} && \pmod{2a} \\
	& \equiv b_2 - V\frac{a_2b_2}{s} - W\frac{b_1b_2+{b_2}^2}{2s} + V\frac{a_2b_1}{s} + W\frac{b_1b_2 + \Delta}{2s} && \pmod{2a} \\
	& \equiv b_2 + V\frac{a_2(b_1-b_2)}{s} + W\frac{\Delta - {b_2}^2}{2s} && \pmod{2a} \\
	& \equiv b_2 + V\frac{2a_2(b_1-b_2)}{2s} + W\frac{2a_2(\Delta - {b_2}^2)}{2a_2 \cdot 2s} && \pmod{2a} \\
	& \equiv b_2 + \frac{2a_2}{s} \left( V\frac{b_1-b_2}{2} + W\frac{\Delta - {b_2}^2}{4a_2} \right) && \pmod{2a}.
\end{alignat*}
Let $c_2 = ({b_2}^2 - \Delta)/4a_2$ and $U = (V(b_1-b_2)/2 - Wc_2) \bmod{(a_1/s)}$ and we have
\[
	b \equiv b_2 + \frac{2a_2}{s} U \pmod{2a},
\]
which completes the derivation of Equation \ref{eq:idealProductB}.  Note that the product ideal $\mathfrak a \mathfrak b$ is not a reduced representative and that the storage needed can be as much as twice that of the ideal factors $\mathfrak a$ and $\mathfrak b$.


%%%%%%%%%%
% NUCOMP %
%%%%%%%%%%
\subsection{Fast Ideal Multiplication (NUCOMP)}
\label{subsec:nucomp}

Shanks \cite{Shanks1989} gives an algorithm for multiplying two ideal class representatives such that their product is reduced or almost reduced.  The algorithm is known as NUCOMP and stands for ``New COMPosition''.  This algorithm is often faster in practice as the intermediate numbers are smaller and the final product requires fewer (often no) applications of the reduction operator to be converted to reduced form. The description of NUCOMP provided here is a high level description of the algorithm based on \cite[pp.119-123]{Jacobson2009}.

Equations \ref{eq:idealProductS}, \ref{eq:idealProductA}, and \ref{eq:idealProductB} from the previous subsection give a solution to the ideal product $\mathfrak a \mathfrak b = s[a, (b+\sqrt\Delta)/2]$.  We begin with the observation (\cite[p.119]{Jacobson2009}) that the fraction $(b/2)/a$ is roughly equal to the fraction $sU / a_1$ where $U$ is given by Equation \ref{eq:idealProductU}:
\[
	\frac{b}{2a} = \frac{b_2 + 2Ua_2/s}{2a_1a_2/s^2} 
	= \frac{s^2 b_2+s2Ua_2}{2a_1a_2}
	= \frac{s^2b_2}{2a_1a_2} + \frac{sU}{a_1}
	\approx \frac{sU}{a_1}.
\]
Following \cite[pp.120-121]{Jacobson2009}, we develop the simple continued fraction expansion of $sU/a_1 = \langle q_0, q_1, \dots, q_i, \phi_{i+1} \rangle$ using the recurrences
\begin{align*}
	q_i &= \floor{R_{i-2} ~/~ R_{i-1}} \\
	R_i &= R_{i-2} - q_i R_{i-1} \\
	C_i &= C_{i-2} - q_i C_{i-1}
\end{align*}
until we have $R_i$ and $R_{i-1}$ such that
\begin{equation}
\label{eq:nucompBound}
	R_i < \sqrt{a_1/a_2} ~ |\Delta/4|^{1/4} < R_{i-1}.
\end{equation}
Initial values for the recurrence are given by
\[
	\matrixtt{R_{-2}}{R_{-1}}{C_{-2}}{C_{-1}} = \matrixtt{sU}{a_1}{-1}{0}.
\]
We then compute
\begin{align*}
	M_1 &= \frac{R_i a_2 + sC_i(b_1-b_2)/2}{a_1}, \\
	M_2 &= \frac{R_i (b_1+b_2)/2 - s C_i c_2}{a_1}, \\
	a &= (-1)^{i+1} (R_i M_1  - C_i M_2), \\
	b &= \left( \frac{2(R_i a_2 /s - C_{i-1} a)}{C_i} - b_2 \right) \bmod 2a
\end{align*}
for the reduced or almost reduced product $\mathfrak a \mathfrak b = [a, (b + \sqrt\Delta)/2]$.  Note that this procedure assumes that $\mathcal N(\mathfrak a) \ge \mathcal N(\mathfrak b)$ and that if $a_1 < \sqrt{a_1/a_2} ~ |\Delta/4|^{1/4}$ then $R_{-1}$ and $R_{-2}$ satisfy Equation \ref{eq:nucompBound} and we compute the product $\mathfrak a \mathfrak b$ as in the previous subsection without expanding the simple continued fraction $sU/a_1$.

Our implementation of fast ideal multiplication includes some optimizations on the above technique.  Equation \ref{eq:idealProductS} requires that we compute $\gcd(a_1, a_2, (b_1 + b_2)/2)$. Since $\gcd(a_1, a_2)$ is often equal to 1, we only need compute $\gcd(a_1, a_2, (b_1 + b_2)/2)$ when $\gcd(a_1, a_2) \neq 1$. Also, by Equation \ref{eq:idealProductS}, we have that $s ~|~ a_1$ and $s ~|~ a_2$, so we reduce both $a_1$ and $a_2$ by $s$ throughout. Finally, the first coefficient, $Y$, from Equation \ref{eq:idealProductS} is never used, and so we do not compute it. We give pseudo-code in Algorithm \ref{alg:nucomp}. 

% NUCOMP
\begin{algorithm}[h]
\caption{NUCOMP -- Fast Ideal Multiplication. Based on \cite[pp.441-443]{Jacobson2009}.}
\label{alg:nucomp}
\begin{algorithmic}[1]
\REQUIRE Reduced representatives $\mathfrak a = [a_1, (b_1+\sqrt\Delta)/2]$, $\mathfrak b = [a_2, (b_2+\sqrt\Delta)/2]$ \\ with $c_1 = ({b_1}^2-\Delta)/4a_1$, $c_2 = ({b_2}^2-\Delta)/4a_2$, and discriminant $\Delta$.
\ENSURE A reduced or almost reduced representative $\mathfrak a \mathfrak b$.
\STATE ensure $\mathcal N(\mathfrak a) < \mathcal N(\mathfrak b)$ by swapping $\mathfrak a$ with $\mathfrak b$ if $a_1 < a_2$
\STATE compute $s'$ and $V'$ such that $s' = \gcd(a_1, a_2) = Y'a_1 + V'a_2$ for $s', Y', V' \in \ZZ$
\STATE $s \gets 1$
\STATE $U \gets V'(b_1 - b_2)/2 \bmod a_1$
\IF {$s' \neq 1$}
	\STATE compute $s, V$, and $W$ \\
	       such that $s = \gcd(s', (b_1 + b_2)/2) = Vs' + W(b_1 + b_2)/2$ for $V, W \in \ZZ$
	\STATE $(a_1, a_2) \gets (a_1/s, a_2/s)$
	\STATE $U \gets (VU - Wc_2) \bmod a_1$
\ENDIF
\IF {$a_1 < \sqrt{a_1/a_2} ~ |\Delta/4|^{1/4}$}
	\STATE $a \gets a_1a_2$
	\STATE $b \gets (2a_2U + b_2) \bmod{2a}$
	\RETURN $[a, (b+\sqrt\Delta)/2]$
\ENDIF
\STATE $\matrixtt{R_{-2}}{R_{-1}}{C_{-2}}{C_{-1}} \gets \matrixtt{U}{a_1}{-1}{0}$
\STATE find $i$ such that $R_i < \sqrt{a_1/a_2} ~ |\Delta/4|^{1/4} < R_{i-1}$ using the recurrences: \\
$q_i = \floor{R_{i-2} ~/~ R_{i-1}}$ \\
$R_i = R_{i-2}-q_i R_{i-1}$ \\
$C_i=C_{i-2}-q_i C_{i-1}$
\STATE $M_1 \gets (R_i a_2 + C_i(b_1-b_2)/2)/a_1$
\STATE $M_2 \gets (R_i (b_1+b_2)/2 -sC_i c_2)/a_1$
\STATE $a \gets (-1)^{i+1}(R_i M_1 - C_i M_2)$
\STATE $b \gets ((2(R_i a_2 - C_{i-1} a)/C_i) - b_2) \bmod{2a}$
\RETURN $[a, (b+\sqrt\Delta)/2]$
\end{algorithmic}
\end{algorithm}


%%%%%%%%%%
% NUDUPL %
%%%%%%%%%%
\subsection{Fast Ideal Squaring (NUDUPL)}
\label{subsec:nudupl}

When the two input ideals for multiplication are the same, as is the case when squaring, much of the arithmetic simplifies.  For reduced ideals $\mathfrak a = [a_1, (b_1 + \sqrt\Delta)/2]$ and $\mathfrak b = [a_2, (b_2 + \sqrt\Delta)/2]$, we have $a_1=a_2$ and $b_1=b_2$.  Equations \ref{eq:idealProductS} and \ref{eq:idealProductU} simplify to
\begin{align*}
	s &= \gcd(a_1, b_1) = Xa_1 + Yb_1 \\
	U &= -Yc_1 \bmod (a_1/s).
\end{align*}
We then compute the continued fraction expansion of $sU/a_1$, but on the bound
\[
	R_i < |\Delta/4|^{1/4} < R_{i-1}.
\]
Computing the ideal class representative simplifies as well -- we have
\begin{align*}
	M_1 &= R_i, \\
	M_2 &= \frac{R_i b_1 - sC_i c_1}{a_1}, \\
	a &= (-1)^{i+1}({R_i}^2 - C_i M_2), \\
	b &= \left(\frac{2(R_i a_1/s  - C_{i-1} a)}{C_i} - b_1 \right) \bmod{2a}.
\end{align*}
As before, the representative $[a, (b+\sqrt\Delta)/2]$ is either reduced or almost reduced.  \break Pseudo-code for our implementation is given in algorithm \ref{alg:nudupl}.

% NUDUPL.
\begin{algorithm}[h]
\caption{NUDUPL -- Fast Ideal Squaring.}
\label{alg:nudupl}
\begin{algorithmic}[1]
\REQUIRE Reduced representative $\mathfrak a = [a_1, (b_1+\sqrt\Delta)/2]$ \\
         with $c_1 = ({b_1}^2-\Delta)/4a_1$ and discriminant $\Delta$.
\ENSURE A reduced or almost reduced representative $\mathfrak a^2$.
\STATE compute $s$ and $Y$ such that $s = \gcd(a_1, b_1) = Xa_1 + Yb_1$ for $s,X,Y \in \ZZ$
\STATE $a_1 \gets a_1/s$
\STATE $U \gets -Yc_1 \bmod a_1$
\IF {$a_1 < |\Delta/4|^{1/4}$}
	\STATE $a \gets {a_1}^2$
	\STATE $b \gets (2Ua_1 + b_1) \bmod 2a$
	\RETURN $[a, (b + \sqrt\Delta)/2]$
\ENDIF
\STATE $\matrixtt{R_{-2}}{R_{-1}}{C_{-2}}{C_{-1}} \gets \matrixtt{U}{a_1}{-1}{0}$
\STATE Find $i$ such that $R_i < |\Delta/4|^{1/4} < R_{i-1}$ using the recurrences: \\
       $q_i = \floor{R_{i-2}/R_{i-1}}$ \\
       $R_i = R_{i-2}-q_i R_{i-1}$ \\
       $C_i=C_{i-2}-q_i C_{i-1}$
\STATE $M_2 \gets (R_i b_1 -sC_i c_1)/a_1$
\STATE $a \gets (-1)^{i+1}({R_i}^2 - C_i M_2)$
\STATE $b \gets (2(R_i a_1 + C_{i-1} a)/C_i) \bmod{2a}$
\RETURN $[a, (b+\sqrt\Delta)/2]$
\end{algorithmic}
\end{algorithm}


%%%%%%%%%%
% NUCUBE %
%%%%%%%%%%
\subsection{Fast Ideal Cubing (NUCUBE)}\label{subsec:nucube}

When we consider binary-ternary representations of exponents, cubing is required.  In general, if we want to compute ${\mathfrak a}^3$ for an ideal class representative $\mathfrak a = [a_1, (b_1+\sqrt\Delta)/2]$, we can take advantage of the simplification that happens when expanding the computation of ${\mathfrak a}^2 \mathfrak a$.  Here we provide a high level description of a technique for cubing based on similar ideas to NUCOMP and NUDUPL, namely that of computing the quotients of a continued fraction expansion.  A detailed description and analysis of this technique can be found in \cite{Imbert2010}.

Similar to ideal squaring, we compute integers $s'$ and $Y'$ such that
\[
s' = \gcd(a_1, b_1) = X'a_1 + Y'b_1.
\]
Note that $X'$ is unused. If $s' \neq 1$ we compute
\[
s = \gcd(s'a_1, {b_1}^2 - a_1c_1) = Xs'a_1 + Y({b_1}^2 - a_1c_1)
\]
for $s, X, Y \in \ZZ$.  If $s' = 1$ then let $s = 1$ too.  We then compute $U$ using
\[
U = \begin{cases}
		Y'c_1(Y'(b_1 - Y'c_1a_1) - 2) \bmod {a_1}^2 & \textrm{ if } s' = 1 \\
		-c_1(XY'a_1+Yb_1) \bmod {a_1}^2/s & \textrm{ otherwise.}
    \end{cases}
\]
We then develop the simple continued fraction expansion of $sU/{a_1}^2$ until
\[
	R_i < \sqrt{a_1}|\Delta/4|^{1/4} < R_{i-1}.
\]
Finally, we can compute the reduced or almost reduced representative $\mathfrak a^3 = [a, (b + \sqrt\Delta)/2]$ using the equations
\begin{align*}
	M_1 &= \frac{(R_ia_1 + C_iUa_1)}{{a_1}^2}, \\
	M_2 &= \frac{R_i(b_1 + Ua_1) - sC_ic_1}{{a_1}^2}, \\
	a &= (-1)^{i+1} R_i M_1 - C_i M_2, \\
	b &= \left( \frac{2(R_ia_1/s - C_{i-1}a)}{C_i} - b_1 \right) \bmod 2a.
\end{align*}

As always, the ideal $[a, (b + \sqrt\Delta)/2]$ is reduced or almost reduced. Pseudo-code for our implementation of fast ideal cubing is given in Algorithm \ref{alg:nucube}.

% NUCUBE
\begin{algorithm}[h]
\caption{NUCUBE -- Fast Ideal Cubing. Adapted from \cite[p.26]{Imbert2010}.}
\label{alg:nucube}
\begin{algorithmic}[1]
\REQUIRE A reduced representative $\mathfrak a = [a_1, (b_1+\sqrt\Delta)/2]$.
\ENSURE A reduced or almost reduced representative $\mathfrak a^3$.
\STATE compute $s'$ and $Y'$ such that $s' = \gcd(a_1, b_1) = X'a_1 + Y'b_1$ for $s', X', Y' \in \ZZ$
\IF{$s' = 1$}
	\STATE $s \gets 1$
	\STATE $U \gets Y'c_1(Y'(b_1 - Y'c_1a_1) - 2) \bmod {a_1}^2$
\ELSE
	\STATE compute $s, X$, and $Y$ such that $s = \gcd(s'a_1, {b_1}^2 - a_1c_1) = Xs'a_1 + Y({b_1}^2 - a_1c_1)$ for $s, X, Y \in \ZZ$
	\STATE $U \gets -c_1(XY'a_1+Yb_1) \bmod {a_1}^2/s$
\ENDIF
\IF {${a_1}^2/s < \sqrt{a_1} ~ |\Delta/4|^{1/4}$}
	\STATE $a \gets {a_1}^3/s^2$
	\STATE $b \gets (b_1 + 2Ua_1/s) \bmod 2a$
	\RETURN $[a, (b+\sqrt\Delta)/2]$
\ENDIF
\STATE $\matrixtt{R_{-2}}{R_{-1}}{C_{-2}}{C_{-1}} \gets \matrixtt{U}{({a_1}^2/s)}{-1}{0}$
\STATE Find $i$ such that $R_i < \sqrt{a_1} |\Delta/4|^{1/4} < R_{i-1}$ using the recurrences: \\
       $q_i = \floor{R_{i-2}/R_{i-1}}$ \\
       $R_i = R_{i-2}-q_i R_{i-1}$ \\
       $C_i=C_{i-2}-q_i C_{i-1}$
\STATE $M_1 \gets (R_ia_1 + C_iUa_1) / {a_1}^2$
\STATE $M_2 \gets (R_i(b_1 + Ua_1) - sC_ic_1) / {a_1}^2$
\STATE $a \gets (-1)^{i+1} R_i M_1 - C_i M_2$
\STATE $b \gets (2(R_ia_1/s - C_{i-1}a)/C_i - b_1) \bmod 2a$
\RETURN $[a, (b+\sqrt\Delta)/2]$
\end{algorithmic}
\end{algorithm}

In the next chapter, we'll discuss some exponentiation techniques that make use of the ideal arithmetic presented in this chapter, namely fast multiplication, squaring, and cubing.


%%%%%%%%%%%%%%%%%%
% CHAPTER 3      %
% EXPONENTIATION %
%%%%%%%%%%%%%%%%%%
\chapter{Exponentiation}
\label{chap:exponentiation}

Given a group $G$, an element $g \in G$, and an integer $n$, computing $g^n$ is a common operation and is known as exponentiation.  Diffie-Hellman key exchange is an example that uses exponentiation whereby two parties can jointly establish a shared secret key over an insecure channel.  An application discussed in detail in this thesis is that of computing the order of a group element.  Our approach is to exponentiate a group element to the product, $P$, of several small primes.  The result is an element whose order is likely to not be divisible by any of these primes. The order of this new element is then computed using a variant of Shanks' baby-step giant-step algorithm where only powers relatively prime to $P$ are computed.  Determining the order of an element can be useful in computing the structure of a group, or in factoring an integer associated with a group.  Being able to exponentiate faster implies that the entire computation can complete more quickly.

In Sections \ref{section:binary} and \ref{section:naf} we discuss standard exponentiation techniques that rely on a base 2 representation of the exponent.  In Section \ref{section:dbns} we introduce double-base number systems, which, as the name implies, are number systems that make use of multiple bases in the representation of a number.  We pay particular attention to double-base representations that use bases 2 and 3, since in our implementation of ideal class group arithmetic the cost of squaring is less than the cost of multiplying, and the cost of cubing is less than the cost of multiplying an element with its square. For this reason, we distinguish between the number of multiplications, squares, and cubes in an algorithm. In Section \ref{section:dbnsMethods} we discuss some methods to compute double-base representations found in the literature.  


%%%%%%%%%%%%%%%%%%%%%%%%%
% BINARY EXPONENTIATION %
%%%%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\section{Binary Exponentiation}\label{section:binary}
The simplest method of exponentiation is binary exponentiation.  Let $g$ be an element in the group $G$ and $n$ be a positive integer.  We want to compute $g^n \in G$.  We first represent $n$ in binary as
\[
	n = \sum_{i=0}^{\floor{\log_2 n}} b_i 2^i
\]
where $b_i \in \{0, 1\}$ such that $b_i$ represents the $i^{\textrm{th}}$ bit of $n$.   We compute $g^{2^i}$ by repeated squaring of $g$ and compute $g^n$ by computing
\[
	g^n = \prod_{i=0}^{\floor{\log_2 n}} g^{b_i 2^i}.
\]
This description is known as right-to-left binary exponentiation because the result is computed by generating the terms of the product from low order to high order.  The left-to-right variant evaluates the bits of the exponent $n$ from high order to lower order by repeatedly squaring an accumulator and multiplying this with the base element $g$ when $b_i = 1$.  The left-to-right variant has the advantage that one of the values in the multiplication, namely $g$, remains fixed throughout the evaluation.  There also exist windowed variants where $g^w$ is precomputed for each $w$ in some window $0 \le w \le 2^k$ for some $k$ (typically chosen to be cache efficient). The exponent $n$ is then expressed in base $2^k$.  There are numerous sources discussing windowed variants such as (TODO) but we do not discuss these variants further here.

Binary exponentiation algorithms require $\floor{\log_2 n}$ squarings and on average $\floor{\log_2 n}/2$ multiplications, since a multiplication is only necessary when $b_i = 1$ and the probability of $b_i = 1$ is 1/2.

%%%%%%%%%%%%%%%%%%%%%%
% NAF EXPONENTIATION %
%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\section{Non-Adjacent Form Exponentiation}\label{section:naf}

The Non-Adjacent Form (NAF) of an integer is a \emph{signed} base two representation such that no two non-zero terms in the representation are adjacent. Each integer, $n$, has a unique representation in non-adjacent form. Formally, an integer $n$ is represented such that
\[
	n = \sum_{i=0}^{\floor{\log_2 n}+1} s_i 2^i
\]
where $s_i \in \{0, 1, -1\}$ and $s_i \cdot s_{i+1} = 0$. For example, suppose $n = 23814216$.  In binary we have
\begin{equation}\label{eq:binaryEg}
	23814216 = 2^3+2^6+2^{13}+2^{14}+2^{16}+2^{17}+2^{19}+2^{21}+2^{22}+2^{24}
\end{equation}
and in non-adjacent form we have
\begin{equation}\label{eq:nafEg}
	23814216 = 2^3+2^6-2^{13}-2^{15}-2^{18}-2^{20}-2^{23}+2^{25}.
\end{equation}
Similar to the binary case, we can compute $g^n$ using
\[
	g^n = \prod _{i=0}^{\floor{\log_2 n}+1} g^{s_i 2^i}.
\]
Since $s_i$ can be $-1$ and inversion can be expensive, we can instead compute the product as
\[
	g^n = \left( \prod_{i : s_i=1} g^{2^i} \right) \cdot \left( \prod_{i : s_i=-1} g^{2^i} \right)^{-1}
\]
which requires at most one inversion.

A typical method to compute the non-adjacent form of an integer $n$ is to inspect $n$ two bits at a time from least significant to most significant.  Let $n=\sum b_i2^i$ be the binary representation of $n$ and let $j=0$.  If the bit pattern $\langle b_{j+1}, b_j \rangle = 01$, then let $s_j = 1$ and subtract $2^j$ from $n$.  If $\langle b_{j+1}, b_j \rangle = 11$, then let $s_j = -1$ and add $2^j$ to $n$.  When the bit pattern $\langle b_{j+1}, b_j \rangle$ is $00$ or $10$, let $s_j = 0$. Next, increment $j$ and repeat while $n \ne 0$.

In our experiments, we use a variation of the above, originally due to Reitwiesner \cite{reitwiesner1960}, that maintains a carry flag $c$.  Instead of adding $2^i$ to $n$, we set $c = 1$, and instead of subtracting $2^i$ from $n$, we set $c = 0$.  When inspecting $n$ two bits at a time, we consider the bit pattern $(m+c) \bmod 4$ where $m = 2 b_{i+1} + b_i$.  For large enough $n$, the cost of addition and subtraction is reduced from $O(\log n)$ to $O(1)$.  See Algorithm \ref{alg:nafR2LImmutable}.

% R2L NAF EXPONENTIATION
\begin{algorithm}[h]
\caption{Computes $g^n$ using right-to-left non-adjacent form. Reitwiesner \cite{reitwiesner1960}}
\label{alg:nafR2LImmutable}
\begin{algorithmic}[1]
\REQUIRE $g \in G, n \in \ZZgez$
\STATE $c \gets 0$ \COMMENT{carry flag}
\STATE $T \gets g$ \COMMENT{invariant: $T = g^{2^i}$}
\STATE $R \gets 1_G$
\STATE $i \gets 0$
\WHILE {$n \ge 2^i$}
	\IF {$\floor{n/2^i}+c \equiv 1 \pmod 4$}
		\STATE $R \gets R \cdot T$
		\STATE $c \gets 0$
	\ELSIF {$\floor{n/2^i}+c \equiv 3 \pmod 4$}
		\STATE $R \gets R \cdot T^{-1}$
		\STATE $c \gets 1$
	\ENDIF
	\STATE $T \gets T^2$
	\STATE $i \gets i+1$
\ENDWHILE
\IF {$c=1$} \STATE $R \gets R \cdot T$ \ENDIF
\RETURN $R$
\end{algorithmic}
\end{algorithm}

A particular advantage of a non-adjacent form exponentiation over a binary exponentiation is the number of operations required.  While the binary method requires $\floor{\log_2 n}$ squares and on average $\floor{\log_2 n}/2$ multiplications, a non-adjacent form exponentiation requires at most $\floor{\log_2 n}+1$ squares and on average $(\floor{\log_2 n}+1)/3$ multiplications.  To see this, recall that non-adjacent form requires that no two non-zero terms be adjacent.  Consider any two adjacent terms.  The possible outcomes are $(0,0)$, $(s, 0)$, or $(0, s$) where $s \in \{-1, 1\}$. This means that 2/3 of the time, 1/2 of the terms will be non-zero, and so the probability of any given term being non-zero is 1/3.


%%%%%%%%
% DBNS %
%%%%%%%%
\bigbreak
\section{Double-Base Number Systems}\label{section:dbns}

A significant advantage of non-adjacent form over a binary representation is that on average the number of non-zero terms (the density of the representation) is lower.  We can achieve an even lower density on average when we extend the representation to a signed double-base number system (DBNS).  Binary and non-adjacent form are both base 2 number systems.  In the case of a double base number system, as the name suggests, we use two bases.  This system was first introduced by Dimitrov and Cooklev \cite{Dimitrov1995a, Dimitrov1995b}.  Given two coprime integers $p$ and $q$ and some integer $n$, we represent $n$ as the sum and difference of the product of powers of $p$ and $q$,
\begin{equation}\label{eq:generalDbnsForm}
	n = \sum_{i=1}^k s_i p^{a_i} q^{b_i}
\end{equation}
where $s_i \in \{-1, 1\}$ and $a_i, b_i, k \in \ZZgez$.

Since this thesis focuses on exponentiation in the ideal class group, and since we can compute the square of an element faster than multiplying it with itself, and we can compute the cube of an element faster than multiplying its square with itself, we will be particularly interested in bases $p=2$ and $q=3$.  In other words, we will focus on representations of $n$ such that $n = \sum s_i 2^{a_i} 3^{b_i}$.

As an example of a 2,3 double-base representation, consider the number $n=23814216$ again.  Given the bases $p=2$ and $q=3$, \emph{one} possible representation of $n$ is
\begin{equation}\label{eq:chainedEg1}
	23814216 = 2^3 3^3 - 2^4 3^5 + 2^5 3^6  + 2^7 3^7  + 2^9 3^8 + 2^{10} 3^9.
\end{equation}
Another possible representation is
\begin{equation}\label{eq:chainedEg2}
	23814216 = 2^3 3^2 -2^{13} 3^2 +2^{15} 3^6.
\end{equation}
Double-base number systems are highly redundant, and different representations will trade off between cubings, squarings, and the number of terms.  The best representation, in some sense, will depend on the needs of the application.  Later, we shall see some algorithms that take this into account, but many are designed to either find representations quickly, of a special form, or with few terms.

Recall, the binary representation \eqref{eq:binaryEg}, non-adjacent form \eqref{eq:nafEg}, and a 2,3 double-base representation \eqref{eq:chainedEg2} of 23814216 were
\begin{align*}
	23814216 &= 2^3+2^6+2^{13}+2^{14}+2^{16}+2^{17}+2^{19}+2^{21}+2^{22}+2^{24}, & \mbox{using binary} \\
	23814216 &= 2^3+2^6-2^{13}-2^{15}-2^{18}-2^{20}-2^{23}+2^{25}, & \mbox{using NAF} \\
	23814216 &= 2^3 3^2 -2^{13} 3^2 +2^{15} 3^6. & \mbox{using 2,3 DBNS}
\end{align*}
The binary representation has 10 terms, while the non-adjacent form has only 8 terms.  The 2,3 representation given above contains only three terms.  While a non-adjacent form has in expectation $\floor{\log_2 n}/3$ terms and a binary representation has in expectation $\floor{\log_2 n}/2$ terms, both are bounded by $O(\log n)$ in the number of terms.  Both Dimitrov et al \cite{Dimitrov2008} and Ciet and Sica \cite{Ciet2005} give algorithms for 2,3 double-base representations, where they prove that the number of terms is bounded by $O(\log n / \log \log n)$.  For this reason, many algorithms focus on reducing the number of terms in a 2,3 representation.   Naturally, the time to compute a 2,3 double-base exponentiation is further reduced if the corresponding cost to compute $g^2$ is less than the cost to compute $g \cdot g$, or the cost to compute $g^3$ is less than the cost to compute $g^2 \cdot g$. 

%%%%%%%%%%%%%%%%%%%
\bigbreak
\subsection{Chains}

One way to classify algorithms that compute 2,3 representations is by the constraints placed on the \emph{partition} of an integer $n$.  For an example of a partition, consider the 2,3 representation of $23814216 = 2^3 3^2 -2^{13} 3^2 +2^{15} 3^6$.  The terms $2^3 3^2$, $2^{13} 3^2$, and $2^{15} 3^6$ when monotonically increasing by absolute value is a partition of the integer $23814216$.  

\begin{defn}
A partition of an integer $n = x_1 \pm x_2 \pm \cdots \pm x_k$ is \emph{chained} if every term $x_i$ divides every term $x_j$ for $i < j$ and $x_i \le x_j$. A partition is said to be \emph{strictly chained} if it is chained and $x_i$ is \emph{strictly} less than $x_j$ for each $i < j$.
\end{defn}

\noindent
Binary and non-adjacent form are special types of strictly chained partitions, since for any two non-zero terms where $i < j$, we have $x_i = 2^i$, $x_j = 2^j$, $ x_i ~|~ x_j$, and $x_i < x_j$.  The 2,3 representation of $23814216 = 2^3 3^2 - 2^{13} 3^2 + 2^{15} 3^6$ is another example of a strictly chained partition, since $2^3 3^2 ~|~ 2^{13} 3^2 ~|~ 2^{15} 3^6$.

% EXPONENTIATE USING A CHAIN
\begin{algorithm}[h]
\caption{Computes $g^n$ given $n$ as a chained 2,3 partition. TODO: Cite something.}
\label{alg:expWithChain}
\begin{algorithmic}[1]
\REQUIRE $g \in G,$ 
$n = \sum_{i=1}^k s_i2^{a_i}3^{b_i},$ \\
$s_1,...,s_k \in \{-1, 1\},$ 
$0 \le a_1 \le ...\le a_k \in \ZZ,$ 
$0 \le b_1 \le ... \le b_k \in \ZZ.$
\STATE $i \gets 1$
\STATE $a \gets 0$ \COMMENT{current power of 2}
\STATE $b \gets 0$ \COMMENT{current power of 3}
\STATE $T \gets g$ \COMMENT{loop invariant: $T = g^{2^a 3^b}$}
\STATE $R \gets 1_G$
\WHILE {$i \le k$}
	\WHILE {$a < a_i$}
		\STATE $T \gets T^2, a \gets a + 1$
	\ENDWHILE
	\WHILE {$b < b_i$}
		\STATE $T \gets T^3, b \gets b + 1$
	\ENDWHILE
	\STATE $R \gets R \cdot T^{s_i}$ \COMMENT{compose with $T$ or $T^{-1}$}
	\STATE $i \gets i + 1$
\ENDWHILE
\RETURN $R$
\end{algorithmic}
\end{algorithm}

The benefit of restricting 2,3 representations to chained representations is the ease with which one can compute $g^n$ when $n$ is given as a chain.  For example $g^{23814216} = g^{2^3 3^2 - 2^{13} 3^2 + 2^{15} 3^6}$ can be computed by first computing $x_1 = g^{2^3 3^2}$, $x_2 = {x_1}^{2^{10}}$, $x_3 = {x_2}^{2^2 3^4}$, and finally $g^{23814216} = \left(x_1 \cdot x_3\right) \cdot \left(x_2\right)^{-1}$.  Algorithm \ref{alg:expWithChain} can be used to compute $g^n$ for $g \in G$ and $n$ given as a chained 2,3 representation.  The cost of algorithm \ref{alg:expWithChain} is as follows: Let $n$ be defined as $\sum s_i 2^{a_i} 3^{b_i}$, let $max_a = \max \{a_1,...,a_k\}$, and let $max_b = \max \{b_1,...,b_k\}$.  Then we require $max_a$ squares, $max_b$ cubes, $k-1$ multiplications, and at most one inverse.  Since $x_i ~|~ x_{i+1}$, we need only retain $x_i$ in order to compute $x_{i+1}$, and so exponentiation and chain generation can easily be interleaved. For this reason, many algorithms that find 2,3 representations constrain these representations to be chains.  Section \ref{section:dbnsMethods} discusses some algorithms for simultaneously generating and exponentiating with such chains.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\subsection{Exponentiating general 2,3 representations}

Another class of algorithms compute representations without the constraint that larger terms be divisible by smaller terms.  Given a general 2,3 representation for an integer $n = \sum s_i 2^{a_i} 3^{b_i}$, M\'{e}loni and Hasan \cite[Section 3.2]{Meloni2009} use a modification of Yao's Algorithm to achieve the same bound on the number of operations as in algorithm \ref{alg:expWithChain}, but with a bound of $O(\min \{max_a, max_b\})$ on the memory used.  Suppose $max_b < max_a$.  We require the terms to be labelled and sorted such that $a_1 \ge ... \ge a_k$.  The algorithm works by precomputing a table of $T_b = g^{3^b}$ for $0 \le b \le max_b$.  Let $i=1$ and begin with the first term $s_i2^{a_i}3^{b_i}$.  We look up $T_{b_i} = g^{3^{b_i}}$ and, after applying the sign $s_i$, we multiply ${T_{b_i}}^{s_i}$ with the running result.  Let $a_\Delta = a_i - a_{i+1}$ when $i < k$ and $a_\Delta = a_k$ when $i = k$.  It then squares the running result $a_\Delta$ times.  The algorithm removes the term $s_i2^{a_i}3^{b_i}$ from the list of terms, and continues in this way with the next largest $a_i$.  The algorithm terminates when there are no more terms in the list.  Algorithm  \ref{alg:yaos} gives pseudo-code for this approach and requires $O(max_b)$ memory.  When $max_a < max_b$, we use a related algorithm that requires the terms to be sorted such that $b_1 \ge ... \ge b_k$; it precomputes $T_a = g^{2^a}$ for $0 \le a \le max_a$ and works similar to Algorithm \ref{alg:yaos} but with cubing and squaring appropriately swapped.

% EXPONENTIATE USING YAO'S
\begin{algorithm}[h]
\caption{Computes $g^n$ given $n$ in 2,3 representation. M\'{e}loni \cite[Section 3.2]{Meloni2009}.}
\label{alg:yaos}
\begin{algorithmic}[1]
\REQUIRE $g \in G,$ 
$n = \sum_{i=1}^k s_i2^{a_i}3^{b_i},$ \\
$s_1,...,s_k \in \{-1, 1\},$ 
$a_1 \ge ... \ge a_k \in \ZZgez,$ 
$b_1,...,b_k \in \ZZgez.$
\STATE $T_b \gets g^{3^b}$ for $0 \le b \le \max \{ b_1, ..., b_k \}$ \COMMENT{by repeated cubing}
\STATE $R \gets 1_G$
\STATE $i \gets 1$
\WHILE {$i < k$}
	\STATE $R \gets R \cdot {T_{b_i}}^{s_i}$ \COMMENT{compose with $T_{b_i}$ or ${T_{b_i}}^{-1}$}
	\STATE $a_\Delta \gets a_i - a_{i+1}$
	\STATE $R \gets R ^ {2^{a_\Delta}}$ \COMMENT{by squaring $a_\Delta$ number of times}
	\STATE $i \gets i + 1$
\ENDWHILE
\STATE $R \gets R \cdot {T_{b_k}}^{s_k}$
\STATE $R \gets R ^ {2^{a_k}}$ \COMMENT{by squaring $a_k$ number of times}
\RETURN $R$
\end{algorithmic}
\end{algorithm}

For example, the 2,3 representation $23814216 = 2^{15} 3^6 - 2^8 3^5 - 2^4 3^6 + 2^3 3^3$ is sorted by decreasing $a_i$.  The algorithm first computes $T_b = g^{3^b}$ for $0 \le b \le 6$.  Note that it is sufficient to store only the values of $g^{3^{b_i}}$ that actually occur in terms (in this example, we need only store $T_3$, $T_5$, and $T_6$).  Let $R_j$ represent the partial exponentiation of the first $j$ terms with the largest $a_i$ such that $g^{2^{a_{j+1}}}$ is factored out.  Let $R_0 = 1_G$.  In this example, we compute 
\begin{align*}
	R_1 &= \left( T_6 \right)^{2^7} &&\Rightarrow g^{2^7 3^6}, \\
	R_2 &= \left( R_1 {T_5}^{-1} \right)^{2^4} &&\Rightarrow g^{-2^4 3^5 + 2^{11} 3^6}, \\
	R_3 &= \left( R_2 {T_6}^{-1} \right)^{2^1} &&\Rightarrow g^{-2^1 3^6 -2^5 3^5 + 2^{12} 3^6}, \\
	R_4 &= \left( R_3 T_3 \right) ^ {2^3} &&\Rightarrow g^{2^3 3^3 -2^4 3^6 -2^8 3^5 + 2^{15} 3^6},
\end{align*}
as depicted by figure \ref{fig:yao1}.  The result of the computation is $R_4 = g^{23814216}$.  

% figure of exponentiating 23814216 with unchained representation
\begin{figure}[H]
\centering
\includegraphics{yao1}
\caption{The construction of $2^{15} 3^6 - 2^8 3^5 - 2^4 3^6 + 2^3 3^3$ using algorithm \ref{alg:yaos}.  Steps are executed from left-to-right, top-to-bottom.}
\label{fig:yao1}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% METHODS FOR COMPUTING 2,3 CHAINS/REPRESENTATIONS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\section{Methods for computing 2,3 Chains/Representations}
\label{section:dbnsMethods}

Factors influencing the speed of a 2,3 exponentiation are the time to generate the 2,3 chain or representation, and the cost of group operations such as compose, square, and cube. If the exponent is a constant, then we can precompute the chain or representation. Here we discuss some methods from the literature: the first generates strict chains from low order to high order (right-to-left), the second generates representations (chained or unchained) from high order to low order (left-to-right), and the last generates strict chains using a tree-based approach.  For an integer $n$, each successive method introduced below typically requires more time to generate a 2,3 representation, but the representation typically has fewer terms.  As such, these methods show a trade off between the time spent computing a representation and the time spent exponentiating with the representation.  None of these methods take the relative cost of composing, squaring, or cubing into account.  In Chapter \ref{chap:idealExponentiationExperiments} we will look at variations of these algorithms that generate representations that attempt to minimize the cost of exponentiation given the relative costs of group operations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\subsection{Right-to-Left Chains (from low-order to high-order)}
\label{subsec:rtolchains}

The first method we present computes a strictly chained 2,3 partition that is generated from low order to high order and is based on Ciet et al \cite{Ciet2006}.  We begin by recalling the technique for binary exponentiation that computes from low order to high order.  Given an element $g \in G$ and an integer $n$, the function
\begin{align*}
\textrm{bin}(g, n) &= \begin{cases}
               1 & \textrm{if $n = 0$} \\
               {\textrm{bin}(g, n/2)}^2 & \textrm{if $n \equiv 0 \pmod 2$} \\
               \textrm{bin}(g, n-1) \cdot g & \textrm{if $n \equiv 1 \pmod 2$} \\
	       \end{cases}
\end{align*}
will compute the binary exponentiation of $g^n$ from low order to high order. This algorithm will repeatedly remove factors of 2 from $n$.  When $n$ is not divisible by 2, it subtracts 1 such that the input to the recursive call will be divisible by 2.  The recursion terminates with the base case of $n=0$.

We can extend this concept to a 2,3 number system.  We will repeatedly remove factors of 2 from $n$, then repeatedly remove factors of 3 from $n$.  At this point, either $n \equiv 1 \pmod 6$ or $n \equiv 5 \pmod 6$.  When $n \equiv 1 \pmod 6$, we recurse on $n-1$ and the input will be divisible by both 2 and 3.  When $n \equiv 5 \pmod 6$, we recurse on $n+1$.  Again, the input to the recursive call will be divisible by both 2 and by 3.  Using this idea, we can perform a 2,3 exponentiation recursively as
\newcommand{\rtol}{\textrm{r}_2\textrm{l}}
\begin{align*}
\rtol(g, n) &= \begin{cases}
               1 & \textrm{if $n = 0$} \\
               {\rtol(g, n/2)}^2 & \textrm{if $n \equiv 0 \pmod 2$} \\
               {\rtol(g, n/3)}^3 & \textrm{if $n \equiv 0 \pmod 3$} \\
               \rtol(g, n-1) \cdot g & \textrm{if $n \equiv 1 \pmod 3$} \\
               \rtol(g, n+1) \cdot g^{-1} & \textrm{if $n \equiv 2 \pmod 3$}. \\
	       \end{cases}
\end{align*}

There is a non-recursive function with group operations that correspond to those generated by $\rtol$. This is useful when recursion is not possible, or when the exponent $n$ is a constant (since we can precompute the representation of $n$ to save time). Algorithm \ref{alg:rtolDbnsChain} computes the corresponding strictly chained 2,3 partition.  The idea is as follows: let $a = 0$, $b=0$, and $i=1$.  While $n > 0$, repeatedly remove factors of 2 from $n$ and increment $a$ for each factor of 2 removed. Then repeatedly remove factors of 3 from $n$ and increment $b$ for each factor of 3 removed. At this point, either $n \equiv 1 \pmod 6$ or $n \equiv 5 \pmod 6$ and so continue on $n-1$ or $n+1$ respectively.  When we continue on $n-1$, this corresponds to adding the current term, so we set $s_i=1$, and when we continue on $n+1$, this corresponds to subtracting the current term, so we set $s_i=-1$. Let $a_i = a$ and $b_i = b$ and then increment $i$ and then repeat this process while $n > 0$.  We can then use Algorithm \ref{alg:expWithChain} to compute the exponentiation given a strictly chained 2,3 partition. Additionally, since the terms $s_i2^{a_i}3^{b_i}$ are computed in increasing order for $i=1..k$, it is relatively straightforward to interleave the computation of the partition with the computation of the exponentiation for additional speed and memory savings.

% R2L 2,3 CHAIN
\begin{algorithm}[h]
\caption{Computes a 2,3 strictly chained representation from low order to high order. Ciet \cite{Ciet2006}.}
\label{alg:rtolDbnsChain}
\begin{algorithmic}[1]
\REQUIRE $n \in \ZZgez$
%\ENSURE $n=\sum_{i=1}^k s_i2^{a_i}3^{b_i}$ as a strictly chained partition.
\STATE $(a, b) \gets (0, 0)$
\STATE $i \gets 1$
\WHILE {$n > 0$}
	\WHILE {$n \equiv 0 \pmod 2$} 
		\STATE $n \gets n / 2, a \gets a + 1$
	\ENDWHILE
	\WHILE {$n \equiv 0 \pmod 3$}
		\STATE $n \gets n / 3, b \gets b + 1$
	\ENDWHILE
	\IF {$n \equiv 1 \pmod 3$}
		\STATE $n \gets n - 1, s \gets 1$
	\ELSIF {$n \equiv 2 \pmod 3$}
		\STATE $n \gets n + 1, s \gets -1$
	\ENDIF
	\STATE $(s_i, a_i, b_i) \gets (s, a, b)$
	\STATE $i \gets i + 1$
\ENDWHILE
\STATE $k \gets i$
\RETURN $(a_1, b_1, s_1), ..., (a_k, b_k, s_k)$
\end{algorithmic}
\end{algorithm}

To see the correctness of the above procedure, consider a modification to the recursive function $\rtol$ such that it returns a partition of the input $n$ as a list of terms $s_i2^{a_i}3^{b_i}$. When the result of the recursive call is squared, this corresponds to incrementing $a_i$ in each term of the list.  Similarly, when the result is cubed, this corresponds to incrementing $b_i$ in each term of the list. When the result is composed with $g$, we prepend a term of $+1$ to the partition, and when the result is composed with $g^{-1}$, we prepend a term of $-1$ to the partition. Note that since either $n \equiv 0 \pmod 2$ or $n \equiv 0 \pmod 3$ on each iteration of the loop, either $a$ will increase or $b$ will increase. Since every term $|s_i2^{a_i}3^{b_i}|$ is strictly less than $|s_j2^{a_j}3^{b_j}|$ when $i < j$, the partition is strictly chained.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\subsection{Left-to-Right Chains (from high-order to low-order)}

\newcommand{\greedyltor}{\textrm{greedy}}
\newcommand{\greedychain}{\textrm{greedy}'}
\newcommand{\greedybound}{\textrm{greedy}''}
\newcommand{\closest}{\textrm{closest}}

The previous section gave a procedure for generating a strictly chained 2,3 partition for an integer $n$ such that the terms were ordered from smallest absolute value to largest.  Here we present a greedy approach that generates the terms in order of the largest absolute value to the smallest. The general idea is to find a term, $s2^a3^b$, that is closest to the remaining target integer $n$ and then repeat on $n - s2^a3^b$. Let
\[
\closest(n) = s2^a3^b
\]
where $a,b \in \ZZgez$ minimize $\left| |n| - 2^a3^b \right|$ and $s = -1$ when $n < 0$ and $s = 1$ otherwise. A recursive function to greedily compute a 2,3 representation is
\begin{align*}
\greedyltor(n) &= \begin{cases}
              0 & \textrm{if $n = 0$} \\
              \closest(n) + \greedyltor(n - \closest(n)) & \textrm{otherwise}.
          \end{cases}
\end{align*}

\noindent
Note that the representation generated may not be a chained partition, however, we can still use the representation to exponentiate a group element $g \in G$ using Algorithm \ref{alg:yaos}.

In order to generate a chained partition we restrict the maximum powers of 2 and 3 generated by the function $\closest$.  We bound $\closest$, such that it returns the triple
\[
\closest'(n, \amax, \bmax) = (s2^a3^b, a, b)
\]
where $0 \le a \le \amax$, $0 \le b \le \bmax$, $a$ and $b$ minimize $\left| |n| - 2^a3^b \right|$, and $s=-1$ when $n < 0$ and $s=1$ when $n > 0$. Our recursive function is then
\begin{align*}
\greedychain(n, \amax, \bmax) &= \begin{cases}
        0 & \textrm{if $n = 0$} \\
        v + \greedychain(n - v, a, b) & \textrm{where $(v, a, b) = \closest'(n, \amax, \bmax)$}.
    \end{cases}
\end{align*}

\noindent
We present pseudocode in Algorithm \ref{alg:greedyltor}. Note that on successive invocations of $\greedychain$, the absolute value of $v=|s2^a3^b|$ returned by $\closest'$ is monotonically decreasing.  Reversing the terms of the partition gives a chained 2,3 partition of $n$ that we can use to perform exponentiation using Algorithm \ref{alg:expWithChain}.

% GREEDY L2R
\begin{algorithm}[h]
\caption{Greedy left to right representations. Berth\'{e} and Imbert \cite{Berthe2009}.}
\label{alg:greedyltor}
\begin{algorithmic}[1]
\REQUIRE $n, \amax, \bmax \in \{\ZZgez, +\infty\}$ \COMMENT{$+\infty$ for unbounded $a$ or $b$}
\STATE $L \gets \textrm{empty list}$
\WHILE {$n \ne 0$}
	\STATE compute integers $a$ and $b$ that minimize $\left||n| - 2^a3^b \right|$ \\
	       such that $0 \le a \le \amax$ and $0 \le b \le \bmax$
	\STATE $s \gets -1 \textrm{ when } n < 0 \textrm{ and } 1 \textrm{ otherwise}$
	\STATE $\textrm{push }(s, a, b) \textrm{ onto the front of } L$
	\STATE $\textrm{optionally set } (\amax, \bmax) \gets (a, b) \textrm{ when a chain is desired}$
	\STATE $n \gets n - s2^a3^b$
\ENDWHILE
\RETURN $L$
\end{algorithmic}
\end{algorithm}

To compute the 2,3 term closest to $n$, a straightforward approach is to compute the set 
\[
V = \{2^a3^b, 2^{a+1}3^b : 0 \le b \le \ceil{\log_3|n|}, a=\floor{|n/(3^b)|} \},
\]
take the element $v \in V$ that is closest to $|n|$, and take $s \in \{-1, 1\}$ based on the sign of $n$, constraining $a$ and $b$ appropriately based on maximal values permitted. Since the set $V$ contains $O(\log |n|)$ elements, computing the term closest to $n$ by this method takes $\Omega(\log |n|)$ steps.  When $a$ and $b$ are not constrained, and we simply want to compute the 2,3 term closest to $n$, Berth\'{e} and Imbert \cite{Berthe2009} present a method that requires at most $O(\log \log |n|)$ steps. 

Naturally though, non-chained representations tend to have a lower density than chained representations but at the expense of requiring more memory to perform exponentiation.  Since we can exponentiate non-chained representations using Algorithm \ref{alg:yaos} and require memory proportional to the largest values of $a$ and $b$ in the representation, constraining $a$ and $b$ globally over the complete representation can result in representations that exponentiate more quickly in practice. In this case, recursive calls to $\greedychain$ use the original values of $\amax$ and $\bmax$ rather than further constraining $a$ and $b$ based on the values generated by $\closest'$.  Finding the best greedy representation is then a matter of iterating over $\amax$ and $\bmax$ and computing 2,3 representations constrained appropriately.  We will discuss approaches and results of this in Chapter \ref{chap:idealExponentiationExperiments}.



%%%%%%%%%%%%%%%%%%%%%%%%%
\bigbreak
\subsection{Pruned Trees}

The next technique for finding strictly chained 2,3 partitions was suggested by Doche and Habsieger \cite{Doche2008}. The idea is similar to the method for generating chains from right to left as described in Subsection \ref{subsec:rtolchains} above, but this technique differs by generating several possible values that may be further reduced by powers of 2 and 3. The procedure is given in Algorithm \ref{alg:dbnsTree}.  The idea is to maintain a tree, $T$, with at most $B$ leaf nodes. At each iteration, each leaf node $v \in T$ generates two new leaves, $v-1$ and $v+1$, which are then reduced as much as possible by removing factors of 2 and 3.  We then discard any duplicate nodes and all but the smallest $B$ elements generated. The path from the root to the first leaf with a value of 1 represents a chained 2,3 partition of the number $n$.

%%%%%%%%%%%%%
% DBNS TREE %
%%%%%%%%%%%%%
\begin{algorithm}[h]
\caption{Tree-Based Chained 2,3 Partitions. Doche and Habsieger \cite{Doche2008}.}
\label{alg:dbnsTree}
\begin{algorithmic}[1]
\REQUIRE $n \in \ZZgtz$
\STATE $T \gets$ a binary tree on the node $n$
\WHILE {no leaf is 1}
	\FORALL {leaf nodes $v \in T$}
		\STATE insert as a left child $(v - 1)$ with all factors of 2 and 3 removed
		\STATE insert as a right child $(v + 1)$ with all factors of 2 and 3 removed
	\ENDFOR
	\STATE discard any duplicate leaves
	\STATE discard all but the smallest $B$ leaves
\ENDWHILE
\RETURN the chained 2,3 partition generated by the path from the root to the first leaf node containing 1
\end{algorithmic}
\end{algorithm}

Empirically they found that $B=4$ was a good compromise between the length of the chain generated and the time to compute the chain. Larger values of $B$ sometimes produce chains with fewer terms, but take longer to compute. When the number for the target chain is known in advance and precomputation is permitted, a larger value of $B$ can be advantageous since this can lead to fewer terms, which can lead to a cheaper exponentiation.  The downside is that large values of $B$ can be prohibitively expensive even for precomputation when the integer $n$ is quite large.


%%%%%%%%%%%%%
% CHAPTER 4 %
% SUPERSPAR %
%%%%%%%%%%%%%
\chapter{SuperSPAR}
\label{chap:superspar}

A contribution of this thesis is to improve the speed of arithmetic in the ideal class group of imaginary quadratic number fields with an application to integer factoring.  In Chapter \ref{chap:idealArithmetic} we introduced the ideal class group, and in Chapter \ref{chap:exponentiation} we introduced some methods for exponentiation in generic groups.  In this chapter, we make a connection between the two and that of integer factoring.  In Section \ref{sec:spar} we introduce an algorithm, called SPAR, that uses a group isomorphic to the ideal class group to factor an integer associated with the discriminant.  In Section \ref{sec:primorial}, we discuss the primorial steps algorithm for order finding in generic groups that is asymptotically faster than both Pollard's rho method and Shank's baby-steps giant-steps technique.  Finally, in Section \ref{sec:superspar} we reconsider the factoring algorithm SPAR in the context of primorial steps for order finding.  We call this new algorithm SuperSPAR.

%%%%%%%%
% SPAR %
%%%%%%%%
\section{SPAR}
\label{sec:spar}

SPAR is an integer factoring algorithm based on the idea of finding a reduced ambiguous class representative with a discriminant $\Delta$ associated with the integer to be factored.  The algorithm was published by Schnorr and Lenstra in \cite{Schnorr1984}, but was independently discovered by Atkin and Rickert who named it SPAR after Shanks, Pollard, Atkin, and Rickert \cite[p.182]{Jacobson1999}.

\subsection{Ambiguous Forms and the Factorization of the Discriminant}

Following Jacobson \cite{Jacobson1999}, we represent elements of the ideal class group using reduced representative ideals.  We denote the equivalence class $[\mathfrak a]$ for a reduced representative $\mathfrak a$ using the $\ZZ$\mbox{-}module $\mathfrak a = [a, (b + \sqrt\Delta)/2]$. In our implementation we also carry around a third term $c = (b^2 - \Delta)/4a$.

The description of SPAR uses binary quadratic forms. A binary quadratic form is a quadratic form in two variables
\[
	f(x, y) = ax^2 + bxy + cy^2
\]
where $a$, $b$, and $c$ are integer coefficients.  For a given form there is a set of integers represented by $f(x, y)$ for integers $x$ and $y$. Two forms are equivalent if the sets of integers they represent are equivalent \cite[pp.239-240]{Crandall2001}, and these sets are equivalent if and only if there exists an invertible integral linear change of variables that transforms the first form into the second form. Necessarily, two equivalent forms have the same discriminant, which is given as $\Delta = b^2 - 4ac$ and corresponds to the discriminant of our ideal.  Furthermore, as Fr\"olich and Taylor \cite{Frolich1993} show, the form $ax^2 + bxy + cy^2$ is isomorphic to the primitive ideal $[a, (b + \sqrt\Delta)/2]$.  The set of all equivalent forms for a given discriminant form an equivalence class, and as shown by Gau\ss, representatives of equivalence classes of forms can be composed together to form a group, $G(\Delta)$.  In the case of a negative discriminant, each form is equivalent to a unique reduced form \cite[p.241]{Crandall2001}.  Since forms are isomorphic to ideals, the class group of binary quadratic forms with negative discriminant, $G(\Delta)$, is also isomorphic to the ideal class group of imaginary quadratic number fields, $Cl_\Delta$. As such, we adapt our discussion of the SPAR factoring algorithm to use the language of ideal classes.

\begin{defn}
The \emph{ambiguous classes} are the classes $[\mathfrak a]$ such that ${[\mathfrak a]}^2$ is the identity class \cite{Schnorr1984}.  This holds for both the equivalence class of forms and the equivalence class of ideals.  Notice that the identity ideal class $[\mathcal O_\Delta] \in Cl_\Delta$ is an ambiguous class.
\end{defn}

According to \cite{Schnorr1984}, every reduced representative of an ambiguous class with negative discriminant has either $b = 0$, $a = b$, or $a = c$.  Since the discriminant is defined as $\Delta = b^2 - 4ac$, these reduced representatives correspond to a factorization of the discriminant.  We have either
\begin{align*}
\Delta &= 4ac & \textrm{ when } & b = 0, \\
\Delta &= b(b - 4c) & \textrm{ when } & a = b, \textrm{ or} \\
\Delta &= (b - 2a)(b + 2a) & \textrm{ when } & a = c.
\end{align*}
Now suppose we wish to find a factor of an odd integer $N$. Since $\Delta = b^2 - 4ac$ we must have $\Delta \equiv 0, 1 \pmod 4$.  Therefore, set $\Delta = -N$ when $-N \equiv 1 \pmod 4$ and $\Delta = -4N$ otherwise.  This way, $\Delta \equiv 0, 1 \pmod 4$ and $\Delta < 0$. Now, in order to find a factor of $N$ we only need to find a reduced ambiguous class representative for the discriminant $\Delta$ that is not the identity element, since the identity element gives the trivial factorization $1N=N$.

\subsection{Algorithm}
\newcommand{\aclass}{[\mathfrak a]}
\newcommand{\bclass}{[\mathfrak b]}
\newcommand{\cclass}{[\mathfrak c]}
\newcommand{\dclass}{[\mathfrak d]}
\newcommand{\idclass}{[\mathcal O_\Delta]}

In Chapter \ref{chap:idealArithmetic}, we mentioned that for a negative discriminant $\Delta < 0$, the ideal class group $Cl_\Delta$ has a finite number of elements.  This means that for a random ideal class $\aclass$, there exists an integer $m$ such that $\aclass^m = \idclass$. We say that $m$ is the \emph{order} of the element $\aclass$ and denote this $m = \ord(\aclass)$.  When the order is even, then $\bclass = \aclass^{m/2}$ is an ambiguous ideal class.  This follows from the fact that $\bclass^2 = \idclass$.  Therefore, factoring an integer $N$ reduces to the problem of determining the order of a random ideal class $\aclass \in Cl_\Delta$.

The SPAR algorithm works in two stages. The first stage is to pick a random element $\aclass \in Cl_\Delta$ and then exponentiate it to the product of many small odd prime powers $P$, such that $\bclass = \aclass^P$.  If the order of $\aclass$ divides this odd product, then we can compute an ambiguous ideal by repeated squaring of $\bclass$.  If the order of $\aclass$ does not divide $P$, then we perform a random walk on the group generated by the ideal class $\bclass = \aclass^P$.

\begin{defn}
An integer, $x$, is \emph{smooth} with respect to a factor base $B$, if $x$ is the product of elements from the factor base $B$.  Typically $B$ is chosen to be the first $t$ primes such that $B = \{p_1, p_2, ..., p_t\}$ for some value of $t$.
\end{defn}

Following Schnorr and Lenstra \cite{Schnorr1984}, we take the first $t$ primes $p_1 = 2, p_2 = 3, ..., p_t = N^{1/2r}$ for $r = \sqrt{\ln N / \ln \ln N}$.  Let $e_i = \max \{ v : {p_i}^v \le {p_t}^2 \}$ and compute
\[
	\bclass = \aclass^{\prod_{i=2}^t {p_i}^{e_i}},
\]
where $\bclass$ is a reduced representative. Notice that we exponentiate $\aclass$ to the product of only \emph{odd} prime powers.  The reason for this is that if $\ord(\aclass)$ is smooth with respect to the factor base $B = \{{p_i}^{e_i} : 1 \le i \le t\}$, then we can compute $\bclass^{\left(2^k\right)}$ for the smallest $k$ such that $\bclass^{\left(2^k\right)} = \idclass$.  It follows that $\bclass^{\left(2^{k-1}\right)}$ is an ambiguous ideal class and we can attempt to factor $N$.

Since we do not know if $\ord(\aclass)$ is smooth, we instead bound $k$ such that $2^k$ is no larger than the number of elements in the class group $Cl_\Delta$.  According to \cite[p.155]{Jacobson2009}, the number of elements, $h_\Delta$, in the class group $Cl_\Delta$ is bound by
\[
	h_\Delta < \frac{1}{\pi} \sqrt{|\Delta|}\log{|\Delta|} \textrm{ when } \Delta < -4.
\]
Therefore, we only need compute $\bclass^{\left(2^k\right)}$ for the smallest $k \le h_\Delta$ such that $\bclass^{\left(2^k\right)} = \idclass$ if such a $k$ exists. If such a $k$ does not exist, then the algorithm continues with the second stage.

In the first stage, we compute $\bclass = \aclass^{\prod_{i=2}^t {p_i}^{e_i}}$ and $\cclass = \bclass^{\left(2^k\right)}$.  The second stage is a random walk through the cyclic group generated by the ideal class $\cclass$ in an attempt to find the order $h = \ord(\cclass)$.  Let $\langle \cclass \rangle$ be the cyclic group generated by $\cclass$ and let $f : \langle \cclass \rangle \rightarrow \langle \cclass \rangle$ be a function from one representative in the cyclic group to another.  The function $f$ should have the property that if $x$ is know for some $\cclass ^x$, then $y$ can be determined for $\cclass^y = f(\cclass^x)$.  Let $[\mathfrak c_1] = \cclass$ and repeatedly compute
\[
	[\mathfrak c_{i+1}] = f([\mathfrak c_i])
\]
until there is some $j < k$ such that $[\mathfrak c_j] = [\mathfrak c_k]$.  By the function $f$, we can compute $u$ and $v$ such that $[\mathfrak c_j]=\cclass^u$ and $[\mathfrak c_k]=\cclass^v$.  The order of $\cclass$ is then a multiple of $h = v - u$.  We can compute an ambiguous class representative by computing $\dclass = \bclass^h$ and then computing $\dclass^{\left(2^k\right)}$ for the smallest $k \le h_\Delta$ as before.  Assuming that such a $k$ exists, then $\dclass^{\left(2^{k-1}\right)}$ is an ambiguous class representative and we can factor $N$.

\subsection{Complexity}

The original publication of SPAR by Schnorr and Lenstra \cite{Schnorr1984} claimed that every composite integer $N$ could be factored in $o\left(\exp\sqrt{\ln N \ln\ln N}\right)$ bit operations.  This was the first factoring algorithm for which this runtime had been conjectured, and it was also the first for which this conjecture had to be withdrawn \cite{Lenstra1992}.

In the first stage of the algorithm, we exponentiate a random ideal class $\aclass \in Cl_\Delta$ to the product of primes $\prod_{i=2}^t {p_i}^{e_i}$ such that $p_t = N^{1/2r}$ where $r = \sqrt{\ln N / \ln \ln N}$.  Using binary exponentiation, this will take $O(p_t)$ group operations and for a random composite $m \in [0, N]$ will factor $m$ with probability $\ge r^{-r}$ \cite[p.290]{Schnorr1984}. Stage 2 performs a random walk of at most $O(p_t)$ group operations and with probability $\ge (r-2)^{-(r-2)}$ will factor $m$ \cite[p.290]{Schnorr1984}.  Their claim is that if Stage 1 is run on each integer $kN$ for $k \le r^r$, then every composite integer $N$ will be factored within $o\left(\exp \sqrt{ \ln N \ln\ln N } \right)$ bit operations.

This claim was based on a false assumption and had to be later withdrawn.  For a complete discussion, see Lenstra and Pomerance \cite[\S 11]{Lenstra1992}.  In short, the original assumption was that for fixed $N$ and variable $k$, that the class number ($h_\Delta$ for $\Delta = -kN$) was just as likely to be smooth with respect to some largest prime $p_t$ as the class number associated with a random discriminant of approximately the same size.  This assumption meant that one could take both $k$ and $p_t$ to be no larger than $N^{1/2r} = \exp\left(\frac{1}{2}\sqrt{\ln N \ln \ln N}\right)$, leading to an upper bound of $\exp\left(\sqrt{\ln N \ln \ln N}\right)$ for the expected running time.  However, as Lenstra and Pomerance show \cite[\S 11]{Lenstra1992}, this assumption is incorrect for a sufficiently dense sequence of integers $N$.



%%%%%%%%%%%%%%%%%%%
% PRIMORIAL STEPS %
%%%%%%%%%%%%%%%%%%%
\section{Primorial Steps}

Recall that in Stage 1 of SPAR, we compute $\bclass = \aclass^{\prod_{i=2}^t {p_i}^{e_i}}$ and $\cclass = \bclass^{\left(2^k\right)}$.  In Stage 2, we perform a random walk on the cyclic group generated by $\cclass$.  In 

\subsection{How is the primorial bound chosen}

\subsection{Bound on primes}

\subsection{Bound on prime power}

\subsection{How is this done in the original SPAR}

\subsection{How is this done for generic groups}

\subsection{How do we do it (empirically)}


%%%%%%%%%%%%%
% SUPERSPAR %
%%%%%%%%%%%%%
%\bigbreak
\section{SuperSPAR}

\subsection{Complexity}
\subsection{Analysis for generic groups}
\subsection{Analysis for class group of imaginary quadratic number fields}
\subsection{Comparison with original SPAR}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CHAPTER 5                        %
% IDEAL EXPONENTIATION EXPERIMENTS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Ideal Exponentiation Experiments}

A significant contribution of this thesis is to improve the performance of exponentiation in the ideal class group of imaginary quadratic number fields on present day CPUs.  Improvements to exponentiation also include improvements to arithmetic in the class group.  This chapter focuses on the different techniques we used to improve performance and the experimental data that lead us to our implementation.  In Section \ref{sec:eea}, we discuss methods to compute solutions to equations of the form $s = Ua + Vb$ useful for fast ideal multiplication. In Section \ref{sec:specializedTypes}, we discuss specialized implementations of ideal arithmetic for discriminants less than 60-bits, less than 120-bits, and for discriminants with unbounded size. In Section \ref{sec:exponentiation}, we compare various methods to exponentiate ideal representatives to large fixed exponents that are the product of many primes, including many novel approaches to computing double-base representations of numbers.

\section{Extended Euclidean Algorithm}
\label{sec:eea}

In the Subsection on Fast Ideal Multiplication (\ref{subsec:nucomp}) we describe an algorithm for the simultaneous multiplication and reduction of two reduced ideal class representatives.  Much of the computational effort of this algorithm is in computing solutions to Diophantine equations of the form
\[
	s = Ua + Vb
\]
where $a$ and $b$ are fixed integers, and $s$ is the largest positive integer that divides both $a$ and $b$.  We refer to this computation as the \emph{Extended Euclidean Algorithm}.

\subsection{The Euclidean Algorithm}

The Euclidean Algorithm is an algorithm for computing the greatest common divisor (GCD) of two integers and is due to Euclid.  We start with two positive integers $a$ and $b$.  At each iteration of the algorithm, we subtract the smaller of the two numbers from the larger one, until one them is 0. At this point, the non-zero number is the largest divisor of $a$ and $b$.

Since the smaller number may still be smaller after a single iteration of the above algorithm, we can use fewer steps by subtracting an integer multiple. We extend this concept by using a system of equations of the form
\begin{align}
s &= Ua + Vb \label{eq:initialGcd1} \\
t &= Xa + Yb. \label{eq:initialGcd2}
\end{align}
Initially, let
\[
\matrixThreeTwo{s}{U}{V}{t}{X}{Y} = \matrixThreeTwo{a}{1}{0}{b}{0}{1}
\]
and Equations \ref{eq:initialGcd1} and \ref{eq:initialGcd2} hold.  We maintain the invariant that $s \ge t$.  When $s < t$, simply swap rows in the matrix representation above.  At each iteration, subtract $\floor{s/t}$ times the second row from the first, and then swap rows to maintain the invariant.  When $t=0$, the first row of the matrix is a solution such that $s$ is the largest positive divisor of $a$ and $b$.  The algorithm is given in Algorithm \ref{alg:EeaDivRem}.  We can handle negative $a$ and $b$ by using $a' = |a|$ and $b' = |b|$ as inputs and modifying the output such that $U' = U \cdot \sign(a)$ and $V' = V \cdot \sign(b)$ where
\[
	\sign(x) = \begin{cases}
		-1 & \textrm{ when } x < 0 \\
		0 & \textrm{ when } x = 0 \\
		1 & \textrm{ when } x > 0
	\end{cases}.
\]

\begin{algorithm}[h]
\caption{Extended Euclidean Algorithm using Divide with Remainder.}
\label{alg:EeaDivRem}
\begin{algorithmic}[1]
\REQUIRE $a,b \in \ZZ$
\STATE $\matrixThreeTwo{s}{U}{V}{t}{X}{Y} \gets 
        \matrixThreeTwo{a}{1}{0}{b}{0}{1}$
\IF {$t > s$}
	\STATE $\matrixThreeTwo{s}{U}{V}{t}{X}{Y} \gets
	        \matrixtt{0}{1}{1}{0} \cdot \matrixThreeTwo{s}{U}{V}{t}{X}{Y}$
	        \COMMENT{Swap rows. Maintain $s \ge t$.}
\ENDIF
\WHILE {$t \neq 0$}
	\STATE $q \gets \floor{s / t}$
	\STATE $\matrixThreeTwo{s}{U}{V}{t}{X}{Y} \gets \matrixtt{0}{1}{1}{-q} \cdot
		    \matrixThreeTwo{s}{U}{V}{t}{X}{Y}$ \COMMENT{Subtract $q$ times $2^{\textrm{nd}}$ row and swap.}
\ENDWHILE
\RETURN $(s, U, V)$ \COMMENT{Such that $s = Ua + Vb$.}
\end{algorithmic}
\end{algorithm}

To compute the partially reduced coefficients of the product ideal from the Fast Ideal Multiplication Algorithm \ref{alg:nucomp}, we compute the continued fraction expansion of $a/b$ using the recurrences
\begin{align*}
	q_i &= \floor{R_{i-2} ~/~ R_{i-1}} \\
	R_i &= R_{i-2} - q_i R_{i-1} \\
	C_i &= C_{i-2} - q_i C_{i-1}.
\end{align*}
Notice that these recurrences perform the same operation as a single step in the Extended Euclidean Algorithm, as such, we call this the \emph{Partial Extended Euclidean Algorithm}.  The initial and stopping conditions are different, however.  The algorithm is listed in Algorithm \ref{alg:PartialEeaDivRem}.

\begin{algorithm}[h]
\caption{Partial Extended Euclidean Algorithm using Divide with Remainder.}
\label{alg:PartialEeaDivRem}
\begin{algorithmic}[1]
\REQUIRE $a,b, \in \ZZ$ and a termination bound $B \in \ZZ$.
\STATE $\matrixtt{R_0}{C_0}{R_1}{C_1} = \matrixtt{a}{0}{b}{-1}$
\IF {$R_1 > R_0$}
	\STATE $\matrixtt{R_0}{C_0}{R_1}{C_1} \gets
	        \matrixtt{0}{1}{1}{0} \cdot \matrixtt{R_0}{C_0}{R_1}{C_1}$
	        \COMMENT{Swap rows. Maintain $s \ge t$.}
\ENDIF
\WHILE {$R_1 > B$}
	\STATE $q \gets \floor{R_0 / R_1}$
	\STATE $\matrixtt{R_0}{C_0}{R_1}{C_1} \gets \matrixtt{0}{1}{1}{-q} \cdot
		    \matrixtt{R_0}{C_0}{R_1}{C_1}$ \COMMENT{Subtract $q$ times $2^{\textrm{nd}}$ row and swap.}
\ENDWHILE
\RETURN $(R_0, R_1, C_0, C_1)$
\end{algorithmic}
\end{algorithm}

All the operations performed on the matrix
\[
\matrixtt{R_0}{C_0}{R_1}{C_1}
\]
in the Partial Extended GCD are unimodular operations in that the operation can be represented by a 2x2 matrix with determinant either $+1$ or $-1$.  This turns out to be critical as some variations of the Extended Euclidean Algorithm are represented using matrix operations that are not unimodular and so therefore do not have an extension to the Partial Extended Euclidean Algorithm.

\subsection{Lehmer GCD}

\subsection{Right-to-Left Binary GCD (w/o partial)}

\subsection{8-bit Windowed Right-to-Left Binary GCD (w/o partial)}

\subsection{Left-to-Right Binary GCD (w/ partial)}
\subsubsection{Compute $\min_k \{|u-2^k\}$ (in the literature)}
\subsubsection{Compute $|u-2^k|$ where $k = \floor(\log_2u)$ (our method)}

\subsection{32bit, 64bit, 128bit Intel assembler}

\section{Ideal Arithmetic}
\label{sec:specializedTypes}
\subsection{64bit, 128bit, GMP-MPZ}
\subsection{When cubing is better than compose + square}
\subsection{Average time for operations}

\section{Exponentiation}
\label{sec:exponentiation}

\subsection{NAF-R2L}

\subsection{$\pm$ Chains R2l $\pmod 3$}
\begin{itemize}
\item Fast mod 3.
\item Fast div 3
\end{itemize}

\subsection{$\pm$ Chains R2l (mod 36)}
Fast mod 36

\subsection{$\pm$ Chains L2R (Ostrowski based)}

\subsection{Optimal +2, 3 strictly chained partitions (incorporates cost)}

\subsection{$\pm$ 2,3 Representation using best 2,3 approximation of $N$, i.e. $\min\{|N-2^a3^b|\}$}

\subsection{$\pm$ 2,3 Representation using $\min (N \pm 1) / 2^c3^d$}

\subsection{$\pm$ 2,3 Representation using $\min (N \pm 2^a3^b) / 2^c 3^d$}

\subsection{$\pm$ 2,3 Representation using $\min (N \pm 2^a \pm 3^b)/2^c3^d$}

\subsection{Iterating on the \emph{best} $k=16$ results for each of the greedy $\pm$ 2,3 representation algorithms above.}

\subsection{Precomputing best $\pm$ 2,3 representations for 16bit numbers}
\begin{itemize}
\item Algorithm, incorporates cost of compose, square, cube, cache efficiency
\item 16-bit blocking of exponent
\item Comparison of precomputed representations with greedy approaches
\end{itemize}

\subsection{Exponentiation by fixed primorial}

\subsection{Exponentiation by list of prime powers}

\subsection{Exponentiation by general integers}

%%%%%%%%%%%%%%%%%%%%%%%%%
% CHAPTER 6             %
% SUPERSPAR EXPERIMENTS %
%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{SuperSPAR Experiments}

\section{Motivation: How fast can we make SuperSPAR}

\section{Coprime Finding}
\begin{itemize}
\item Wheeling
\item Sieving
\item Delta Tables
\end{itemize}

\section{Exponentiation}
\subsection{Bounds for primorial (bound for prime vs exponent)}
\subsection{Primorial vs Prime Powers}
i.e. is it faster to use the product and one exponentiation or individual primes and many exponentations
\subsection{Best primorial bound for n-bit integers}

\section{Time spent on search vs powering}

\section{Sequential prime ideals vs random prime ideals}

\section{Ratio of prime ideals to multipliers}

\section{Best multipliers to use}

\section{Chained Hashing vs OPen Address Hashing}

\section{Empirical search for primorial and step count}
\begin{itemize}
\item Linear, grid, 2d quadratic, 1d grid + binary search on step count.
\item (Quadratic samples at 1/3 and 2/3 and throws away the larger third)
\end{itemize}

\section{Comparison with other algorithms}
\begin{itemize}
\item Pari/GP
\item Custom SQUFOF
\item GNU MSieve
\item GNU-ECM
\item YAFU
\item Flint
\item Maple
\end{itemize}


%%%%%%%%%%%%%%%%
% BIBLIOGRAPHY %
%%%%%%%%%%%%%%%%
\bibliographystyle{plain}
\bibliography{Bibliography}


\end{document}
